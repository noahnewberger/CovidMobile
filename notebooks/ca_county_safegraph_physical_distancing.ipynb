{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://global-uploads.webflow.com/5baafc2653bd67278f206724/5be267a03f7813daf821b31e_safegraph-logo-hidpi%403x-p-500.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes In Physical Distancing and Personal Mobility in California\n",
    "\n",
    "This notebook is a proof-of-concept to show how the mobility of residents of California is changing in recent days, based on a dataset called [Social Distancing Metrics](https://docs.safegraph.com/docs/social-distancing-metrics) from [SafeGraph](https://safegraph.com).\n",
    "\n",
    "Tools/ tech in this notebook: \n",
    "* pyspark, python pandas, geopandas (for maps)\n",
    "\n",
    "\n",
    "**[Ryan Fox Squire](https://www.linkedin.com/in/ryanfoxsquire/) | Data Scientist @ [SafeGraph](https://safegraph.com/)**\n",
    "\n",
    "ryan@safegraph.com\n",
    "\n",
    "3/30/2020\n",
    "\n",
    "\n",
    "**How to get this data**\n",
    "* SafeGraph is actively donating data and resources to governments, researchers, academics and other organizations working for the public good in response to Covid19. [Click here to get involved](https://docs.google.com/forms/d/e/1FAIpQLSc501xfAzEPADOwRmsdHmu-v8aN14jnKHBmEmdJJcTgRLddqw/viewform).Â "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in /opt/anaconda3/lib/python3.7/site-packages (0.7.0)\n",
      "Requirement already satisfied: shapely in /opt/anaconda3/lib/python3.7/site-packages (from geopandas) (1.7.0)\n",
      "Requirement already satisfied: fiona in /opt/anaconda3/lib/python3.7/site-packages (from geopandas) (1.8.13.post1)\n",
      "Requirement already satisfied: pyproj>=2.2.0 in /opt/anaconda3/lib/python3.7/site-packages (from geopandas) (2.6.1.post1)\n",
      "Requirement already satisfied: pandas>=0.23.0 in /opt/anaconda3/lib/python3.7/site-packages (from geopandas) (1.0.3)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /opt/anaconda3/lib/python3.7/site-packages (from fiona->geopandas) (1.1.1)\n",
      "Requirement already satisfied: munch in /opt/anaconda3/lib/python3.7/site-packages (from fiona->geopandas) (2.5.0)\n",
      "Requirement already satisfied: six>=1.7 in /opt/anaconda3/lib/python3.7/site-packages (from fiona->geopandas) (1.14.0)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/anaconda3/lib/python3.7/site-packages (from fiona->geopandas) (0.5.0)\n",
      "Requirement already satisfied: attrs>=17 in /opt/anaconda3/lib/python3.7/site-packages (from fiona->geopandas) (19.3.0)\n",
      "Requirement already satisfied: click<8,>=4.0 in /opt/anaconda3/lib/python3.7/site-packages (from fiona->geopandas) (7.1.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/anaconda3/lib/python3.7/site-packages (from pandas>=0.23.0->geopandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/anaconda3/lib/python3.7/site-packages (from pandas>=0.23.0->geopandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/anaconda3/lib/python3.7/site-packages (from pandas>=0.23.0->geopandas) (2.8.1)\n",
      "Requirement already satisfied: mapclassify in /opt/anaconda3/lib/python3.7/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.3 in /opt/anaconda3/lib/python3.7/site-packages (from mapclassify) (1.18.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.7/site-packages (from mapclassify) (0.22.1)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.7/site-packages (from mapclassify) (1.0.3)\n",
      "Requirement already satisfied: scipy>=0.11 in /opt/anaconda3/lib/python3.7/site-packages (from mapclassify) (1.4.1)\n",
      "Requirement already satisfied: deprecated in /opt/anaconda3/lib/python3.7/site-packages (from mapclassify) (1.2.10)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-learn->mapclassify) (0.14.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/anaconda3/lib/python3.7/site-packages (from pandas->mapclassify) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/anaconda3/lib/python3.7/site-packages (from pandas->mapclassify) (2.8.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/anaconda3/lib/python3.7/site-packages (from deprecated->mapclassify) (1.11.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas->mapclassify) (1.14.0)\n",
      "Collecting descartes\n",
      "  Downloading descartes-1.1.0-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.7/site-packages (from descartes) (3.1.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib->descartes) (2.4.6)\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib->descartes) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib->descartes) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib->descartes) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib->descartes) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib->descartes) (1.14.0)\n",
      "Installing collected packages: descartes\n",
      "Successfully installed descartes-1.1.0\n"
     ]
    }
   ],
   "source": [
    "! pip install geopandas\n",
    "! pip install mapclassify\n",
    "! pip install descartes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in  [Social Distancing Metrics](https://docs.safegraph.com/docs/social-distancing-metrics) data from SafeGraph\n",
    "\n",
    "(contact ryan@safegraph.com for access to data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in prototype of Social Distancing Metrics (SDM), available from SafeGraph, updated daily with a 3 day lag. \n",
    "\n",
    "* California has 23,159 census block groups (CBGs) and 58 counties. \n",
    "* A CBG is a high resolution census area containing ~ 1000 households. \n",
    "* SDM has a number of interesting summary metrics at the level of each CBG.\n",
    "* SDM includes info like what fraction of people are leaving their home census block groups. \n",
    "* Here we use SDM columns `device_count` and `completely_home_device_count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o72.csv.\n: java.io.IOException: No FileSystem for scheme: s3\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n\tat org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:547)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:545)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.flatMap(List.scala:355)\n\tat org.apache.spark.sql.execution.datasources.DataSource.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:545)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:359)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n\tat org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:619)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4d6e02cb14e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msdm_spark_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s3://sg-c19-response/social-distancing/v2/2020/*/*/*.csv.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue)\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o72.csv.\n: java.io.IOException: No FileSystem for scheme: s3\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n\tat org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:547)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:545)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.flatMap(List.scala:355)\n\tat org.apache.spark.sql.execution.datasources.DataSource.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:545)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:359)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n\tat org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:619)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "sdm_spark_raw = spark.read.option(\"header\", \"true\").csv(\"s3://sg-c19-response/social-distancing/v2/2020/*/*/*.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>origin_census_block_group</th><th>date_range_start</th><th>date_range_end</th><th>device_count</th><th>distance_traveled_from_home</th><th>bucketed_distance_traveled</th><th>median_dwell_at_bucketed_distance_traveled</th><th>completely_home_device_count</th><th>median_home_dwell_time</th><th>bucketed_home_dwell_time</th><th>at_home_by_each_hour</th><th>part_time_work_behavior_devices</th><th>full_time_work_behavior_devices</th></tr></thead><tbody><tr><td>010150007002</td><td>2020-02-03T00:00:00-06:00</td><td>2020-02-04T00:00:00-06:00</td><td>94</td><td>8828</td><td>{\"16001-50000\":16,\">50000\":3,\"<1000\":8,\"2001-8000\":19,\"1001-2000\":4,\"8001-16000\":17}</td><td>{\"16001-50000\":69,\">50000\":30,\"<1000\":42,\"2001-8000\":68,\"1001-2000\":48,\"8001-16000\":88}</td><td>21</td><td>480</td><td>{\"721-1080\":16,\"361-720\":23,\"61-360\":12,\"<60\":24,\">1080\":14}</td><td>[49,46,46,43,44,37,38,31,24,17,19,18,16,20,18,26,31,32,29,35,41,45,46,46]</td><td>13</td><td>16</td></tr><tr><td>010299598001</td><td>2020-02-03T00:00:00-06:00</td><td>2020-02-04T00:00:00-06:00</td><td>172</td><td>18999</td><td>{\"16001-50000\":60,\">50000\":23,\"<1000\":7,\"2001-8000\":13,\"1001-2000\":4,\"8001-16000\":35}</td><td>{\"16001-50000\":61,\">50000\":89,\"<1000\":33,\"2001-8000\":37,\"1001-2000\":53,\"8001-16000\":109}</td><td>24</td><td>715</td><td>{\"721-1080\":55,\"361-720\":39,\"61-360\":16,\"<60\":33,\">1080\":23}</td><td>[113,113,109,111,103,95,83,60,36,34,28,31,26,30,33,53,67,77,91,101,111,115,119,120]</td><td>33</td><td>26</td></tr><tr><td>010299598001</td><td>2020-02-03T00:00:00-05:00</td><td>2020-02-04T00:00:00-05:00</td><td>172</td><td>18999</td><td>{\"16001-50000\":60,\">50000\":23,\"<1000\":7,\"2001-8000\":13,\"1001-2000\":4,\"8001-16000\":35}</td><td>{\"16001-50000\":61,\">50000\":89,\"<1000\":33,\"2001-8000\":37,\"1001-2000\":53,\"8001-16000\":109}</td><td>24</td><td>715</td><td>{\"721-1080\":55,\"361-720\":39,\"61-360\":16,\"<60\":33,\">1080\":23}</td><td>[113,113,109,111,103,95,83,60,36,34,28,31,26,30,33,53,67,77,91,101,111,115,119,120]</td><td>33</td><td>26</td></tr><tr><td>010730109006</td><td>2020-02-03T00:00:00-06:00</td><td>2020-02-04T00:00:00-06:00</td><td>39</td><td>7652</td><td>{\"16001-50000\":4,\">50000\":1,\"<1000\":1,\"2001-8000\":12,\"1001-2000\":6,\"8001-16000\":9}</td><td>{\"16001-50000\":46,\">50000\":4,\"<1000\":150,\"2001-8000\":54,\"1001-2000\":11,\"8001-16000\":110}</td><td>8</td><td>750</td><td>{\"721-1080\":14,\"361-720\":3,\"61-360\":2,\"<60\":10,\">1080\":6}</td><td>[19,23,21,22,25,19,21,19,14,13,10,8,10,12,12,10,14,13,15,14,17,20,19,19]</td><td>7</td><td>7</td></tr><tr><td>011250103023</td><td>2020-02-03T00:00:00-06:00</td><td>2020-02-04T00:00:00-06:00</td><td>157</td><td>10480</td><td>{\"16001-50000\":19,\">50000\":10,\"<1000\":12,\"2001-8000\":30,\"1001-2000\":10,\"8001-16000\":46}</td><td>{\"16001-50000\":132,\">50000\":28,\"<1000\":29,\"2001-8000\":45,\"1001-2000\":74,\"8001-16000\":30}</td><td>18</td><td>650</td><td>{\"721-1080\":52,\"361-720\":35,\"61-360\":18,\"<60\":36,\">1080\":16}</td><td>[98,98,94,94,93,90,83,57,26,23,19,16,19,21,26,35,46,48,71,85,89,92,101,104]</td><td>26</td><td>34</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sdm_spark_raw.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %md ### read in census data\n",
    "# * We may want to combine PDM with census data like county population\n",
    "# * Read in census data for county and census block group populations  (all census data is available in [a convenient CSV download here](https://www.safegraph.com/open-census-data)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-eb540eee2004>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcbg_fips_codes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s3://safegraph-perm/ryan/datasets/openCensusData/metadata/cbg_fips_codes.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcbg_fips_codes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'county_fips'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbg_fips_codes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_fips\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcbg_fips_codes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounty_fips\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcbg_fips_codes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "cbg_fips_codes = spark.read.csv(\"s3://safegraph-perm/ryan/datasets/openCensusData/metadata/cbg_fips_codes.csv\", header=True).toPandas()\n",
    "cbg_fips_codes['county_fips'] = cbg_fips_codes.state_fips + cbg_fips_codes.county_fips\n",
    "cbg_fips_codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>census_block_group</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010010201001</td>\n",
       "      <td>01001</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010010201002</td>\n",
       "      <td>01001</td>\n",
       "      <td>1265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>010010202001</td>\n",
       "      <td>01001</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>010010202002</td>\n",
       "      <td>01001</td>\n",
       "      <td>1236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>010010203001</td>\n",
       "      <td>01001</td>\n",
       "      <td>2364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cbg_population = spark.read.csv(\"s3://safegraph-perm/ryan/datasets/openCensusData/data/cbg_b01.csv\", header=True).toPandas()\n",
    "cbg_population['county_fips'] = cbg_population['census_block_group'].str.slice(start=0, stop=5)\n",
    "cbg_population['population'] = cbg_population['B01001e1'].astype('int')\n",
    "columns = ['census_block_group', 'county_fips', 'population']\n",
    "cbg_population = cbg_population[columns].copy()\n",
    "cbg_population.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_census_block_group</th>\n",
       "      <th>date_range_start</th>\n",
       "      <th>date_range_end</th>\n",
       "      <th>device_count</th>\n",
       "      <th>completely_home_device_count</th>\n",
       "      <th>part_time_work_behavior_devices</th>\n",
       "      <th>full_time_work_behavior_devices</th>\n",
       "      <th>date_start</th>\n",
       "      <th>dt</th>\n",
       "      <th>week</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>state</th>\n",
       "      <th>state_fips</th>\n",
       "      <th>county</th>\n",
       "      <th>class_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010150007002</td>\n",
       "      <td>2020-02-03T00:00:00-06:00</td>\n",
       "      <td>2020-02-04T00:00:00-06:00</td>\n",
       "      <td>94</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>6</td>\n",
       "      <td>01015</td>\n",
       "      <td>AL</td>\n",
       "      <td>01</td>\n",
       "      <td>Calhoun County</td>\n",
       "      <td>H1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010299598001</td>\n",
       "      <td>2020-02-03T00:00:00-06:00</td>\n",
       "      <td>2020-02-04T00:00:00-06:00</td>\n",
       "      <td>172</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>6</td>\n",
       "      <td>01029</td>\n",
       "      <td>AL</td>\n",
       "      <td>01</td>\n",
       "      <td>Cleburne County</td>\n",
       "      <td>H1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>010299598001</td>\n",
       "      <td>2020-02-03T00:00:00-05:00</td>\n",
       "      <td>2020-02-04T00:00:00-05:00</td>\n",
       "      <td>172</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>6</td>\n",
       "      <td>01029</td>\n",
       "      <td>AL</td>\n",
       "      <td>01</td>\n",
       "      <td>Cleburne County</td>\n",
       "      <td>H1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sdm_spark = sdm_spark_raw.select(\"origin_census_block_group\", \"date_range_start\", \"date_range_end\", \n",
    "                                 \"device_count\", \"completely_home_device_count\", \"part_time_work_behavior_devices\", \n",
    "                                 \"full_time_work_behavior_devices\")\n",
    "\n",
    "sdm_df = sdm_spark.toPandas()\n",
    "\n",
    "# convert numerical columns\n",
    "int_columns = ['device_count', 'completely_home_device_count']\n",
    "for int_col in int_columns:\n",
    "  sdm_df[int_col] = sdm_df[int_col].astype('int')\n",
    "\n",
    "#datetime columns\n",
    "sdm_df['date_start'] = sdm_df.date_range_start.str.slice(start=0, stop=10)\n",
    "sdm_df['dt'] = pd.to_datetime(sdm_df['date_start'])\n",
    "sdm_df['week'] = sdm_df.dt.dt.week \n",
    "\n",
    "# join county_fips for county names and states\n",
    "sdm_df['county_fips'] = sdm_df.origin_census_block_group.str.slice(start=0, stop=5) # county is the first 5 digits of the CBG\n",
    "sdm_df = sdm_df.merge(cbg_fips_codes, on='county_fips', how='left')\n",
    "sdm_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggreagte by County and Compute Metrics from PDM columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_fips</th>\n",
       "      <th>week</th>\n",
       "      <th>date_start</th>\n",
       "      <th>device_count</th>\n",
       "      <th>completely_home_device_count</th>\n",
       "      <th>leaving_home</th>\n",
       "      <th>pct_leaving_home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06001</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>61401</td>\n",
       "      <td>16141</td>\n",
       "      <td>45260</td>\n",
       "      <td>73.712155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06001</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>61653</td>\n",
       "      <td>19925</td>\n",
       "      <td>41728</td>\n",
       "      <td>67.682027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06001</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>63435</td>\n",
       "      <td>13872</td>\n",
       "      <td>49563</td>\n",
       "      <td>78.131946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06001</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>60596</td>\n",
       "      <td>13589</td>\n",
       "      <td>47007</td>\n",
       "      <td>77.574427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06001</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>59947</td>\n",
       "      <td>12902</td>\n",
       "      <td>47045</td>\n",
       "      <td>78.477655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ca_df = sdm_df[sdm_df.state=='CA'].copy()\n",
    "sdm_columns = ['device_count', 'completely_home_device_count']  # 'part_time_work_behavior_devices', 'full_time_work_behavior_devices'\n",
    "geo_groupby= 'county_fips'\n",
    "ca_by_county = ca_df.groupby([geo_groupby, 'week', 'date_start'])[sdm_columns].sum().sort_values(by=[geo_groupby, 'week', 'date_start'], ascending=True).reset_index()\n",
    "\n",
    "# compute new metrics\n",
    "ca_by_county['leaving_home'] = ca_by_county['device_count'] - ca_by_county['completely_home_device_count']\n",
    "ca_by_county['pct_leaving_home'] = ca_by_county['leaving_home'] / ca_by_county['device_count'] * 100\n",
    "  \n",
    "ca_by_county.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "1. Visualize % Residents Leaving Home Day by Day (raw data)\n",
    "2. Visualize % Residents Leaving Home Day by Day (smoothed, compared to February Baseline)\n",
    "3. Visualize 1 and 2 on Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_plot(df, metric, series, x_axis='date_start', ylim=None, legend=False, ylabel=None):\n",
    "  plt.rcParams['figure.figsize'] = [8, 5]\n",
    "  df2plot = df.pivot(index=x_axis, columns=series, values=metric).reset_index()\n",
    "  f = plt.figure()\n",
    "  df2plot.plot(x=x_axis, ylim=ylim, legend=legend, ax=f.gca())\n",
    "  if(ylabel):\n",
    "    plt.ylabel(ylabel)\n",
    "  else:\n",
    "    plt.ylabel(metric)\n",
    "  return(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>county_fips</th>\n",
       "      <th>date_start</th>\n",
       "      <th>06001</th>\n",
       "      <th>06003</th>\n",
       "      <th>06005</th>\n",
       "      <th>06007</th>\n",
       "      <th>06009</th>\n",
       "      <th>06011</th>\n",
       "      <th>06013</th>\n",
       "      <th>06015</th>\n",
       "      <th>06017</th>\n",
       "      <th>06019</th>\n",
       "      <th>06021</th>\n",
       "      <th>06023</th>\n",
       "      <th>06025</th>\n",
       "      <th>06027</th>\n",
       "      <th>06029</th>\n",
       "      <th>06031</th>\n",
       "      <th>06033</th>\n",
       "      <th>06035</th>\n",
       "      <th>06037</th>\n",
       "      <th>06039</th>\n",
       "      <th>06041</th>\n",
       "      <th>06043</th>\n",
       "      <th>06045</th>\n",
       "      <th>06047</th>\n",
       "      <th>06049</th>\n",
       "      <th>06051</th>\n",
       "      <th>06053</th>\n",
       "      <th>06055</th>\n",
       "      <th>06057</th>\n",
       "      <th>06059</th>\n",
       "      <th>06061</th>\n",
       "      <th>06063</th>\n",
       "      <th>06065</th>\n",
       "      <th>06067</th>\n",
       "      <th>06069</th>\n",
       "      <th>06071</th>\n",
       "      <th>06073</th>\n",
       "      <th>06075</th>\n",
       "      <th>06077</th>\n",
       "      <th>06079</th>\n",
       "      <th>06081</th>\n",
       "      <th>06083</th>\n",
       "      <th>06085</th>\n",
       "      <th>06087</th>\n",
       "      <th>06089</th>\n",
       "      <th>06091</th>\n",
       "      <th>06093</th>\n",
       "      <th>06095</th>\n",
       "      <th>06097</th>\n",
       "      <th>06099</th>\n",
       "      <th>06101</th>\n",
       "      <th>06103</th>\n",
       "      <th>06105</th>\n",
       "      <th>06107</th>\n",
       "      <th>06109</th>\n",
       "      <th>06111</th>\n",
       "      <th>06113</th>\n",
       "      <th>06115</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>73.712155</td>\n",
       "      <td>82.539683</td>\n",
       "      <td>71.772429</td>\n",
       "      <td>72.709671</td>\n",
       "      <td>71.199654</td>\n",
       "      <td>71.482412</td>\n",
       "      <td>74.809322</td>\n",
       "      <td>66.052842</td>\n",
       "      <td>75.467633</td>\n",
       "      <td>72.538138</td>\n",
       "      <td>73.381877</td>\n",
       "      <td>71.106758</td>\n",
       "      <td>71.027431</td>\n",
       "      <td>71.794872</td>\n",
       "      <td>71.324568</td>\n",
       "      <td>70.916454</td>\n",
       "      <td>68.212181</td>\n",
       "      <td>70.334572</td>\n",
       "      <td>74.187280</td>\n",
       "      <td>71.928166</td>\n",
       "      <td>76.760739</td>\n",
       "      <td>69.460227</td>\n",
       "      <td>68.353994</td>\n",
       "      <td>72.790737</td>\n",
       "      <td>67.875648</td>\n",
       "      <td>75.163399</td>\n",
       "      <td>72.565338</td>\n",
       "      <td>75.331192</td>\n",
       "      <td>75.631399</td>\n",
       "      <td>78.317468</td>\n",
       "      <td>77.362580</td>\n",
       "      <td>70.595691</td>\n",
       "      <td>74.353562</td>\n",
       "      <td>73.184060</td>\n",
       "      <td>76.910244</td>\n",
       "      <td>74.045665</td>\n",
       "      <td>76.181433</td>\n",
       "      <td>73.349459</td>\n",
       "      <td>73.213366</td>\n",
       "      <td>77.847520</td>\n",
       "      <td>77.628521</td>\n",
       "      <td>75.420290</td>\n",
       "      <td>74.184905</td>\n",
       "      <td>75.149303</td>\n",
       "      <td>72.805206</td>\n",
       "      <td>61.261261</td>\n",
       "      <td>64.321839</td>\n",
       "      <td>74.475607</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>73.464920</td>\n",
       "      <td>73.558689</td>\n",
       "      <td>72.666859</td>\n",
       "      <td>69.098712</td>\n",
       "      <td>71.389896</td>\n",
       "      <td>73.299958</td>\n",
       "      <td>76.809878</td>\n",
       "      <td>75.754201</td>\n",
       "      <td>70.546487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>67.682027</td>\n",
       "      <td>57.377049</td>\n",
       "      <td>62.996778</td>\n",
       "      <td>67.659012</td>\n",
       "      <td>64.132809</td>\n",
       "      <td>64.888337</td>\n",
       "      <td>68.472276</td>\n",
       "      <td>64.948454</td>\n",
       "      <td>67.552624</td>\n",
       "      <td>67.261355</td>\n",
       "      <td>66.827309</td>\n",
       "      <td>63.600000</td>\n",
       "      <td>65.052398</td>\n",
       "      <td>64.411028</td>\n",
       "      <td>66.763047</td>\n",
       "      <td>66.750967</td>\n",
       "      <td>59.812383</td>\n",
       "      <td>64.117647</td>\n",
       "      <td>70.260953</td>\n",
       "      <td>65.382176</td>\n",
       "      <td>73.444613</td>\n",
       "      <td>64.705882</td>\n",
       "      <td>66.184074</td>\n",
       "      <td>67.917973</td>\n",
       "      <td>60.779221</td>\n",
       "      <td>72.873194</td>\n",
       "      <td>67.353927</td>\n",
       "      <td>69.109731</td>\n",
       "      <td>66.824752</td>\n",
       "      <td>72.768235</td>\n",
       "      <td>70.491236</td>\n",
       "      <td>59.771574</td>\n",
       "      <td>68.226703</td>\n",
       "      <td>67.096950</td>\n",
       "      <td>68.277241</td>\n",
       "      <td>67.927922</td>\n",
       "      <td>69.640332</td>\n",
       "      <td>68.811821</td>\n",
       "      <td>66.939836</td>\n",
       "      <td>71.439405</td>\n",
       "      <td>70.992551</td>\n",
       "      <td>68.211620</td>\n",
       "      <td>68.572756</td>\n",
       "      <td>68.680710</td>\n",
       "      <td>65.857202</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>59.332113</td>\n",
       "      <td>67.794111</td>\n",
       "      <td>68.427574</td>\n",
       "      <td>66.760386</td>\n",
       "      <td>66.991701</td>\n",
       "      <td>66.197183</td>\n",
       "      <td>59.459459</td>\n",
       "      <td>66.849723</td>\n",
       "      <td>64.344942</td>\n",
       "      <td>69.863882</td>\n",
       "      <td>69.137303</td>\n",
       "      <td>64.744646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>78.131946</td>\n",
       "      <td>87.692308</td>\n",
       "      <td>76.890080</td>\n",
       "      <td>78.032522</td>\n",
       "      <td>74.989456</td>\n",
       "      <td>75.980392</td>\n",
       "      <td>78.814924</td>\n",
       "      <td>77.406523</td>\n",
       "      <td>78.911043</td>\n",
       "      <td>76.835811</td>\n",
       "      <td>78.988942</td>\n",
       "      <td>75.969597</td>\n",
       "      <td>74.512252</td>\n",
       "      <td>77.311961</td>\n",
       "      <td>75.204709</td>\n",
       "      <td>74.787234</td>\n",
       "      <td>72.254335</td>\n",
       "      <td>75.663717</td>\n",
       "      <td>76.867149</td>\n",
       "      <td>75.298554</td>\n",
       "      <td>79.142469</td>\n",
       "      <td>76.196990</td>\n",
       "      <td>73.019126</td>\n",
       "      <td>75.433867</td>\n",
       "      <td>70.437018</td>\n",
       "      <td>81.337481</td>\n",
       "      <td>75.290719</td>\n",
       "      <td>77.964727</td>\n",
       "      <td>78.038033</td>\n",
       "      <td>80.359390</td>\n",
       "      <td>80.262084</td>\n",
       "      <td>69.191919</td>\n",
       "      <td>76.869981</td>\n",
       "      <td>76.024258</td>\n",
       "      <td>79.540230</td>\n",
       "      <td>75.852202</td>\n",
       "      <td>78.456211</td>\n",
       "      <td>75.044767</td>\n",
       "      <td>75.725959</td>\n",
       "      <td>79.921438</td>\n",
       "      <td>79.284750</td>\n",
       "      <td>77.104269</td>\n",
       "      <td>78.104249</td>\n",
       "      <td>77.295584</td>\n",
       "      <td>75.984211</td>\n",
       "      <td>65.600000</td>\n",
       "      <td>69.265846</td>\n",
       "      <td>77.048499</td>\n",
       "      <td>78.191959</td>\n",
       "      <td>76.246883</td>\n",
       "      <td>76.919918</td>\n",
       "      <td>77.709968</td>\n",
       "      <td>73.127753</td>\n",
       "      <td>74.166538</td>\n",
       "      <td>74.605154</td>\n",
       "      <td>78.689993</td>\n",
       "      <td>78.691626</td>\n",
       "      <td>76.234639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>77.574427</td>\n",
       "      <td>77.358491</td>\n",
       "      <td>75.258918</td>\n",
       "      <td>77.073595</td>\n",
       "      <td>75.641624</td>\n",
       "      <td>75.753604</td>\n",
       "      <td>78.779709</td>\n",
       "      <td>72.894737</td>\n",
       "      <td>79.466667</td>\n",
       "      <td>76.257172</td>\n",
       "      <td>76.709957</td>\n",
       "      <td>74.699810</td>\n",
       "      <td>72.707460</td>\n",
       "      <td>76.769025</td>\n",
       "      <td>74.512380</td>\n",
       "      <td>74.308364</td>\n",
       "      <td>70.431211</td>\n",
       "      <td>74.569319</td>\n",
       "      <td>76.925338</td>\n",
       "      <td>75.037594</td>\n",
       "      <td>77.986595</td>\n",
       "      <td>70.781250</td>\n",
       "      <td>71.853211</td>\n",
       "      <td>74.703277</td>\n",
       "      <td>64.207650</td>\n",
       "      <td>75.822368</td>\n",
       "      <td>74.226324</td>\n",
       "      <td>76.826632</td>\n",
       "      <td>77.848723</td>\n",
       "      <td>80.358795</td>\n",
       "      <td>81.578470</td>\n",
       "      <td>70.936639</td>\n",
       "      <td>77.230326</td>\n",
       "      <td>76.204223</td>\n",
       "      <td>80.682226</td>\n",
       "      <td>76.241727</td>\n",
       "      <td>79.207991</td>\n",
       "      <td>76.767436</td>\n",
       "      <td>76.662417</td>\n",
       "      <td>79.859178</td>\n",
       "      <td>80.273334</td>\n",
       "      <td>78.260870</td>\n",
       "      <td>78.830793</td>\n",
       "      <td>78.393770</td>\n",
       "      <td>75.673899</td>\n",
       "      <td>68.181818</td>\n",
       "      <td>68.631271</td>\n",
       "      <td>78.055242</td>\n",
       "      <td>78.596020</td>\n",
       "      <td>76.868878</td>\n",
       "      <td>76.213275</td>\n",
       "      <td>78.161280</td>\n",
       "      <td>75.467290</td>\n",
       "      <td>74.916532</td>\n",
       "      <td>75.265487</td>\n",
       "      <td>79.357494</td>\n",
       "      <td>79.629240</td>\n",
       "      <td>75.577640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>78.477655</td>\n",
       "      <td>76.923077</td>\n",
       "      <td>75.432526</td>\n",
       "      <td>78.780220</td>\n",
       "      <td>74.474886</td>\n",
       "      <td>77.747253</td>\n",
       "      <td>79.608916</td>\n",
       "      <td>73.153779</td>\n",
       "      <td>80.672701</td>\n",
       "      <td>77.215836</td>\n",
       "      <td>76.404494</td>\n",
       "      <td>75.817133</td>\n",
       "      <td>73.491124</td>\n",
       "      <td>79.448276</td>\n",
       "      <td>75.773948</td>\n",
       "      <td>75.516848</td>\n",
       "      <td>71.937262</td>\n",
       "      <td>77.593032</td>\n",
       "      <td>77.777807</td>\n",
       "      <td>76.125672</td>\n",
       "      <td>80.282242</td>\n",
       "      <td>76.443769</td>\n",
       "      <td>74.171939</td>\n",
       "      <td>76.020363</td>\n",
       "      <td>71.720117</td>\n",
       "      <td>76.833333</td>\n",
       "      <td>76.078215</td>\n",
       "      <td>78.531196</td>\n",
       "      <td>79.533484</td>\n",
       "      <td>81.565264</td>\n",
       "      <td>82.347881</td>\n",
       "      <td>73.181170</td>\n",
       "      <td>78.002324</td>\n",
       "      <td>76.768706</td>\n",
       "      <td>81.025825</td>\n",
       "      <td>77.010175</td>\n",
       "      <td>79.442166</td>\n",
       "      <td>77.429121</td>\n",
       "      <td>76.229508</td>\n",
       "      <td>81.068041</td>\n",
       "      <td>80.723531</td>\n",
       "      <td>78.467527</td>\n",
       "      <td>78.760529</td>\n",
       "      <td>77.914182</td>\n",
       "      <td>76.284672</td>\n",
       "      <td>71.844660</td>\n",
       "      <td>68.941642</td>\n",
       "      <td>78.543948</td>\n",
       "      <td>79.152692</td>\n",
       "      <td>77.023722</td>\n",
       "      <td>78.479894</td>\n",
       "      <td>76.457749</td>\n",
       "      <td>68.779343</td>\n",
       "      <td>75.192788</td>\n",
       "      <td>76.858777</td>\n",
       "      <td>79.858394</td>\n",
       "      <td>79.864061</td>\n",
       "      <td>75.229124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = ca_by_county.copy()\n",
    "df2plot = df.pivot(index='date_start', columns='county_fips', values='pct_leaving_home').reset_index()\n",
    "df2plot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'pct_leaving_home'\n",
    "make_plot(ca_by_county, metric, 'county_fips', ylim=(0,100), ylabel='% Residents Leaving Home')\n",
    "display(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_groupby = 'county_fips'\n",
    "ca_select = ca_by_county[[geo_groupby, 'week', 'date_start', 'device_count', 'leaving_home', 'pct_leaving_home']]\n",
    "\n",
    "metric = 'pct_leaving_home'\n",
    "ca_select = ca_select.sort_values(by=[geo_groupby,'date_start'])\n",
    "\n",
    "window_size=7\n",
    "for group in np.sort(ca_select[geo_groupby].unique()):\n",
    "  ca_select.loc[ca_select[geo_groupby]==group, metric] =  ca_select.loc[ca_select[geo_groupby]==group, metric].copy().rolling(window=window_size, center=False).mean()\n",
    "baseline_week = 7 # 7== week of Feb 10th\n",
    "week10avg = ca_select[ca_select.week==baseline_week].groupby([geo_groupby])[metric].mean().to_frame(name='baseline').reset_index()\n",
    "\n",
    "ca_select = ca_select.merge(week10avg, on=geo_groupby)\n",
    "ca_select[metric+'_baselined'] = (ca_select[metric] -  ca_select['baseline'])\n",
    "make_plot(ca_select[ca_select.date_start>'2020-02-07'], metric+'_baselined', geo_groupby, x_axis='date_start', ylim=(-30,30), ylabel='% Residents Leaving Home \\n(Change Since Wk of Feb 10th)')\n",
    "display(plt.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## % Residents Leaving Home On a Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>GEO_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LSAD</th>\n",
       "      <th>CENSUSAREA</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001</td>\n",
       "      <td>0500000US01001</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>County</td>\n",
       "      <td>594.436</td>\n",
       "      <td>POLYGON ((-86.49677 32.34444, -86.71790 32.402...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01009</td>\n",
       "      <td>0500000US01009</td>\n",
       "      <td>01</td>\n",
       "      <td>009</td>\n",
       "      <td>Blount</td>\n",
       "      <td>County</td>\n",
       "      <td>644.776</td>\n",
       "      <td>POLYGON ((-86.57780 33.76532, -86.75914 33.840...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01017</td>\n",
       "      <td>0500000US01017</td>\n",
       "      <td>01</td>\n",
       "      <td>017</td>\n",
       "      <td>Chambers</td>\n",
       "      <td>County</td>\n",
       "      <td>596.531</td>\n",
       "      <td>POLYGON ((-85.18413 32.87053, -85.12342 32.772...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01021</td>\n",
       "      <td>0500000US01021</td>\n",
       "      <td>01</td>\n",
       "      <td>021</td>\n",
       "      <td>Chilton</td>\n",
       "      <td>County</td>\n",
       "      <td>692.854</td>\n",
       "      <td>POLYGON ((-86.51734 33.02057, -86.51596 32.929...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01033</td>\n",
       "      <td>0500000US01033</td>\n",
       "      <td>01</td>\n",
       "      <td>033</td>\n",
       "      <td>Colbert</td>\n",
       "      <td>County</td>\n",
       "      <td>592.619</td>\n",
       "      <td>POLYGON ((-88.13999 34.58170, -88.13925 34.587...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# County geometry (boundary) data is available from the government and hosted many places on the internet\n",
    "counties_raw = gpd.read_file('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json')\n",
    "counties_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join geos to dataframe\n",
    "\n",
    "Also, we pick a specific window to visualize on the map (week ending Mar 23rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>GEO_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LSAD</th>\n",
       "      <th>CENSUSAREA</th>\n",
       "      <th>geometry</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>week</th>\n",
       "      <th>date_start</th>\n",
       "      <th>device_count</th>\n",
       "      <th>leaving_home</th>\n",
       "      <th>pct_leaving_home</th>\n",
       "      <th>baseline</th>\n",
       "      <th>pct_leaving_home_baselined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06005</td>\n",
       "      <td>0500000US06005</td>\n",
       "      <td>06</td>\n",
       "      <td>005</td>\n",
       "      <td>Amador</td>\n",
       "      <td>County</td>\n",
       "      <td>594.583</td>\n",
       "      <td>POLYGON ((-120.99550 38.22541, -121.02708 38.3...</td>\n",
       "      <td>06005</td>\n",
       "      <td>13</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>1547</td>\n",
       "      <td>960</td>\n",
       "      <td>62.623171</td>\n",
       "      <td>74.945730</td>\n",
       "      <td>-12.322558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06021</td>\n",
       "      <td>0500000US06021</td>\n",
       "      <td>06</td>\n",
       "      <td>021</td>\n",
       "      <td>Glenn</td>\n",
       "      <td>County</td>\n",
       "      <td>1313.947</td>\n",
       "      <td>POLYGON ((-122.93765 39.79816, -122.04647 39.7...</td>\n",
       "      <td>06021</td>\n",
       "      <td>13</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>1069</td>\n",
       "      <td>674</td>\n",
       "      <td>65.705567</td>\n",
       "      <td>76.380681</td>\n",
       "      <td>-10.675114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "date2plot = '2020-03-24' # This will be the end-date of a 7 day average\n",
    "data2plot = ca_select[ca_select.date_start == date2plot].copy()\n",
    "map_df = counties_raw.merge(data2plot, left_on='id', right_on='county_fips')\n",
    "map_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Maps\n",
    "\n",
    "* We make 3 maps about % Residents Leaving Home \n",
    "  * 1) Baseline in February\n",
    "  * 2) Mid March (many fewer residents are leaving home)\n",
    "  * 3) Change between 1 and 2\n",
    "  \n",
    "Important Caveat: Small counties have smaller sample sizes and therefore produce estimates that are higher variance and less reliable. Expect the smallest counties to have the most extreme values. One way to reduce the variance of our estimates would be to use hierchical modeling / partial-pooling, but this is not implemented here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_chloropleth_map(gpd, column2plot, cmap, scheme='Quantiles', scheme_kwds = None, legend_title=None):\n",
    "    # for schemes options see: https://github.com/pysal/mapclassify\n",
    "    plt.rcParams['figure.figsize'] = [8, 8]\n",
    "    f = plt.figure()\n",
    "    gpd.plot(column=column2plot, \n",
    "                 legend=True, legend_kwds={'loc': 'upper right', 'title':legend_title },\n",
    "                 cmap=cmap, \n",
    "                 scheme=scheme, classification_kwds=scheme_kwds, \n",
    "                 edgecolor='black',\n",
    "                 ax=f.gca()) \n",
    "    plt.show()\n",
    "    return(True)\n",
    "\n",
    "# These functions were required to correct some buggyness of the geopandas plot colormap scheme functions so that we can have the same colormap across maps\n",
    "def get_hack_polygon(name):\n",
    "  # this is a kluge to force the floor or ceiling on the colormap during visualization\n",
    "  hack_df = pd.DataFrame({'NAME' : [name], 'geometry': pd.Series(['POLYGON((-120.30831 33.99925,-120.27810 33.98331,-120.29732 33.96737, -120.34951 33.97420,-120.30831 33.99925))'])})   # This is a made-up polygon next to catalina island\n",
    "  hack_df['geometry'] = hack_df['geometry'].apply(wkt.loads)\n",
    "  hack_gpd = gpd.GeoDataFrame(hack_df, geometry=hack_df['geometry'])\n",
    "  return(hack_gpd)\n",
    "\n",
    "from shapely import wkt\n",
    "def add_kluge_polygon_with_fixed_value(df_, metric, forced_value, name='hack_polygon'):\n",
    "  df = pd.concat([df_, get_hack_polygon(name=name)], sort=True).reset_index()\n",
    "  df.loc[df.NAME==name, metric] = forced_value\n",
    "  return(df)\n",
    "\n",
    "def set_floor_and_ceiling_colormap(df_, metric, bins):\n",
    "  df = df_.copy()\n",
    "  df = add_kluge_polygon_with_fixed_value(df, metric, my_bins[0], name='bottom')\n",
    "  df = add_kluge_polygon_with_fixed_value(df, metric, my_bins[-1], name='top')# This forces the color-map to extend to bottom\n",
    "  return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bins = [50, 55, 60, 65, 70, 75, 80, 85]\n",
    "this_color_map = plt.cm.get_cmap('Greens') \n",
    "metric='baseline'\n",
    "gdp_plot = set_floor_and_ceiling_colormap(map_df, metric, my_bins)\n",
    "plot_chloropleth_map(gdp_plot, \n",
    "                     metric, \n",
    "                     this_color_map, \n",
    "                     scheme='EqualInterval',\n",
    "                     scheme_kwds={'k':len(my_bins)-1}, \n",
    "                     legend_title='Fraction Residents Leaving \\nHome Daily (baseline)'.format(date2plot))\n",
    "display(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bins = [50.0, 55.0, 60.0, 65.0, 70.0, 75.0, 80.0, 85.0]\n",
    "this_color_map = plt.cm.get_cmap('Greens') \n",
    "metric='pct_leaving_home'\n",
    "gdp_plot = set_floor_and_ceiling_colormap(map_df, metric, my_bins)\n",
    "plot_chloropleth_map(gdp_plot, \n",
    "                     metric, \n",
    "                     this_color_map, \n",
    "                     scheme='EqualInterval',\n",
    "                     scheme_kwds={'k':len(my_bins)-1}, \n",
    "                     legend_title='Fraction Residents Leaving \\nHome Daily (Wk ending {0})'.format(date2plot))\n",
    "display(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse = True\n",
    "my_bins = [-30, -25, -20, -15, -10, -5, 0]\n",
    "this_color_map = plt.cm.get_cmap('Reds') # \n",
    "\n",
    "metric = 'pct_leaving_home_baselined'\n",
    "if(inverse):\n",
    "  gdp_plot = set_floor_and_ceiling_colormap(map_df, metric, my_bins)\n",
    "  my_bins = np.flip(np.array(my_bins)*-1).tolist()\n",
    "  gdp_plot[metric+'_inv'] = gdp_plot[metric]*-1\n",
    "  \n",
    "plot_chloropleth_map(gdp_plot, \n",
    "                     metric+'_inv', \n",
    "                     this_color_map, \n",
    "                     scheme='EqualInterval',\n",
    "                     scheme_kwds={'k':len(my_bins)-1}, \n",
    "                     legend_title='% Decrease in Residents Leaving \\nHome (since Wk of Feb 10th)')\n",
    "display(plt.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO:\n",
    "\n",
    "* CA counties have drastically different sample sizes. Implement a hierchical model (partial pooling across counties) to shrink the extreme rate estimates from small sample size. \n",
    "* Using Weekly Patterns, build a similar view of change in visits to point-of-interest. POI visits should be correlated with residents leaving home, but does it provide additional useful insights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contact SafeGraph\n",
    "\n",
    "* SafeGraph is actively donating data and resources to governments, researchers, academics and other organizations working for the public good in response to Covid19. [Click here to get involved](https://docs.google.com/forms/d/e/1FAIpQLSc501xfAzEPADOwRmsdHmu-v8aN14jnKHBmEmdJJcTgRLddqw/viewform).Â \n",
    "\n",
    "\n",
    "* datastories@safegraph.com\n",
    "* ryan@safegraph.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "ca_county_safegraph_physical_distancing",
  "notebookId": 1488638
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
