{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from state_cleaner import *\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import json\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/samismalling/Documents/mobility-report-data-extractor-master/CovidMobile'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../..')\n",
    "os.chdir('CovidMobile')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_to_county = pd.read_csv('./data/ZIP-COUNTY-FIPS_2017-06.csv')\n",
    "parks = pd.read_csv('./data/parks_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "955"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fips = parks['FIPS'].unique()\n",
    "fips = fips[1:]\n",
    "len(fips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_to_zips = dict()\n",
    "for fip in fips:\n",
    "    fips_to_zips[int(fip)] = list(fips_to_county[fips_to_county['STCOUNTYFP']==fip]['ZIP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(locationid, datasetid, begin_date, end_date, mytoken, base_url):\n",
    "    token = {'token': mytoken}\n",
    "    \n",
    "    #passing as string instead of dict because NOAA API does not like percent encoding\n",
    "    params = 'datasetid='+str(datasetid)+'&'+'locationid='+str(locationid)+'&'+'startdate='+str(begin_date)+'&'+'enddate='+str(end_date)+'&'+'limit=25'+'&datatypeid=TOBS,PRCP'\n",
    "    \n",
    "    r = requests.get(base_url+params, headers=token)\n",
    "    #print(\"Request status code: \"+str(r.status_code))\n",
    "\n",
    "    try:\n",
    "        #results comes in json form. Convert to dataframe\n",
    "        df = pd.DataFrame.from_dict(r.json()['results'])\n",
    "        #print(\"Successfully retrieved \"+str(len(df['station'].unique()))+\" stations\")\n",
    "        dates = pd.to_datetime(df['date'])\n",
    "\n",
    "        return df\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def already_exists(fip):\n",
    "    #Checks to see if the fip data is already in the database\n",
    "    if conn.noaaweather.records.count_documents({ 'FIPS': fip }, limit = 1) != 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "z = dict(itertools.islice(fips_to_zips.items(), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admin', 'config', 'local', 'mydb', 'noaaweather']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pymongo\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "conn=pymongo.MongoClient()\n",
    "db = conn.noaaweather\n",
    "records = db.records\n",
    "conn.list_database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request status code: 200\n"
     ]
    }
   ],
   "source": [
    "baseurl = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?'\n",
    "mytoken = 'NVPWXeGxislWKqThiizoffNjnPtUtAcT'\n",
    "databaseid = 'GHCND'\n",
    "begindate = '2020-03-01'\n",
    "enddate = '2020-05-01'\n",
    "newdf = get_weather('ZIP:'+str(6673), databaseid,begindate,enddate,mytoken,baseurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = fips_to_zips[6053]\n",
    "for code in codes:\n",
    "    try:\n",
    "        newdf = get_weather('ZIP:'+str(code), databaseid,begindate,enddate,mytoken,baseurl)\n",
    "        fip_weather = fip_weather.append(newdf)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_fips = [9001,9003,9005,9007,9009,9011,9013,9015,22075,22095,23001,23003,23005,23007,\n",
    "              23009,23011,23017,23019,23025,23031,25001,25003,25005,25009,25011,25013,25015,\n",
    "              25017,25021,25023,25025,25027,26025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9001\n",
      "9003\n",
      "9005\n",
      "9007\n",
      "9009\n",
      "9011\n",
      "9013\n",
      "9015\n",
      "22075\n",
      "22095\n",
      "23001\n",
      "23003\n",
      "23005\n",
      "23007\n",
      "23009\n",
      "23011\n",
      "23017\n",
      "23019\n",
      "23025\n",
      "23031\n",
      "25001\n",
      "25003\n",
      "25005\n",
      "25009\n",
      "25011\n",
      "25013\n",
      "25015\n",
      "25017\n",
      "25021\n",
      "25023\n",
      "25025\n",
      "25027\n",
      "26025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:33: DeprecationWarning: count is deprecated. Use estimated_document_count or count_documents instead. Please note that $where must be replaced by $expr, $near must be replaced by $geoWithin with $center, and $nearSphere must be replaced by $geoWithin with $centerSphere\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11267\n",
      "26029\n",
      "11287\n",
      "26033\n",
      "11324\n",
      "26049\n",
      "11376\n",
      "26055\n",
      "11401\n",
      "26061\n",
      "11446\n",
      "26065\n",
      "11489\n",
      "26075\n",
      "11535\n",
      "26077\n",
      "11581\n",
      "26081\n",
      "11635\n",
      "26087\n",
      "11683\n",
      "26093\n",
      "11713\n",
      "26099\n",
      "11752\n",
      "26103\n",
      "11777\n",
      "26111\n",
      "11790\n",
      "26115\n",
      "11830\n",
      "26121\n",
      "11886\n",
      "26123\n",
      "11936\n",
      "26125\n",
      "11990\n",
      "26127\n",
      "12015\n",
      "26139\n",
      "12040\n",
      "26143\n",
      "12065\n",
      "26145\n",
      "12095\n",
      "26153\n",
      "12108\n",
      "26147\n",
      "12121\n",
      "26161\n",
      "12157\n",
      "26163\n",
      "12211\n",
      "27001\n",
      "12241\n",
      "27003\n",
      "12301\n",
      "27007\n",
      "12330\n",
      "27013\n",
      "12378\n",
      "27019\n",
      "12422\n",
      "27021\n",
      "12461\n",
      "27025\n",
      "12504\n",
      "27035\n",
      "12554\n",
      "27037\n",
      "12614\n",
      "27041\n",
      "12672\n",
      "27049\n",
      "12725\n",
      "27053\n",
      "12787\n",
      "27059\n",
      "12848\n",
      "27075\n",
      "12861\n",
      "27097\n",
      "12896\n",
      "27109\n",
      "12953\n",
      "27111\n",
      "13007\n",
      "27115\n",
      "13044\n",
      "27123\n",
      "13094\n",
      "27131\n",
      "13126\n",
      "27139\n",
      "13182\n",
      "27141\n",
      "13213\n",
      "27137\n",
      "13252\n",
      "27145\n",
      "13279\n",
      "27147\n",
      "13305\n",
      "27163\n",
      "13361\n",
      "27171\n",
      "13412\n",
      "28033\n",
      "13437\n",
      "28047\n",
      "13469\n",
      "28049\n",
      "13508\n",
      "28059\n",
      "13539\n",
      "28075\n",
      "13578\n",
      "28089\n",
      "13615\n",
      "28111\n",
      "13628\n",
      "28121\n",
      "13687\n",
      "28149\n",
      "13694\n",
      "29019\n",
      "13722\n",
      "29031\n",
      "13765\n",
      "29037\n",
      "13794\n",
      "29043\n",
      "13835\n",
      "29047\n",
      "13861\n",
      "29071\n",
      "13886\n",
      "29077\n",
      "13921\n",
      "29093\n",
      "13962\n",
      "29095\n",
      "13995\n",
      "29097\n",
      "14034\n",
      "29099\n",
      "14060\n",
      "29131\n",
      "14095\n",
      "29145\n",
      "14131\n",
      "29165\n",
      "14157\n",
      "29167\n",
      "14186\n",
      "29183\n",
      "14234\n",
      "29187\n",
      "14264\n",
      "29510\n",
      "14292\n",
      "29189\n",
      "14325\n",
      "29213\n",
      "14350\n",
      "30013\n",
      "14396\n",
      "30029\n",
      "14421\n",
      "30031\n",
      "14437\n",
      "30049\n",
      "14472\n",
      "30057\n",
      "14485\n",
      "30063\n",
      "14512\n",
      "30111\n",
      "14545\n",
      "31025\n",
      "14594\n",
      "31055\n",
      "14651\n",
      "31109\n",
      "14703\n",
      "31153\n",
      "14732\n",
      "32510\n",
      "14768\n",
      "32003\n",
      "14803\n",
      "32005\n",
      "14842\n",
      "32007\n",
      "14855\n",
      "32023\n",
      "14871\n",
      "32031\n",
      "14917\n",
      "33001\n",
      "33003\n",
      "33005\n",
      "33007\n",
      "33009\n",
      "33011\n",
      "33013\n",
      "33015\n",
      "33017\n",
      "34001\n",
      "34003\n",
      "34005\n",
      "34007\n",
      "34009\n",
      "34011\n",
      "34013\n",
      "34015\n",
      "34017\n",
      "34019\n",
      "34021\n",
      "34023\n",
      "34025\n",
      "34027\n",
      "34029\n",
      "34031\n",
      "34033\n",
      "34035\n",
      "34037\n",
      "34039\n",
      "34041\n",
      "35001\n",
      "14942\n",
      "35005\n",
      "14967\n",
      "35009\n",
      "14992\n",
      "35015\n",
      "15005\n",
      "35025\n",
      "15030\n",
      "35027\n",
      "15056\n",
      "35029\n",
      "15059\n",
      "35035\n",
      "15084\n",
      "35045\n",
      "15108\n",
      "35043\n",
      "15133\n",
      "35049\n",
      "15166\n",
      "35055\n",
      "15194\n",
      "35061\n",
      "15219\n",
      "36001\n",
      "15246\n",
      "36005\n",
      "36007\n",
      "15291\n",
      "36009\n",
      "15317\n",
      "36013\n",
      "15348\n",
      "36027\n",
      "15387\n",
      "36029\n",
      "15449\n",
      "36031\n",
      "15478\n",
      "36039\n",
      "15512\n",
      "36047\n",
      "15537\n",
      "36055\n",
      "15595\n",
      "36059\n",
      "15646\n",
      "36061\n",
      "15679\n",
      "36063\n",
      "15712\n",
      "36065\n",
      "15753\n",
      "36067\n",
      "15788\n",
      "36069\n",
      "15844\n",
      "36071\n"
     ]
    }
   ],
   "source": [
    "baseurl = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?'\n",
    "mytoken = 'NVPWXeGxislWKqThiizoffNjnPtUtAcT'\n",
    "databaseid = 'GHCND'\n",
    "begindate = '2020-03-01'\n",
    "enddate = '2020-05-01'\n",
    "\n",
    "tic = time.perf_counter()\n",
    "weather = pd.DataFrame()\n",
    "for fip, codes in fips_to_zips.items():\n",
    "    if not already_exists(fip) and fip not in empty_fips: #check to make sure not double counting data\n",
    "        print(fip)\n",
    "        fip_weather = pd.DataFrame()\n",
    "        for code in codes:\n",
    "            try:\n",
    "                newdf = get_weather('ZIP:'+str(code), databaseid,begindate,enddate,mytoken,baseurl)\n",
    "                fip_weather = fip_weather.append(newdf)\n",
    "            except:\n",
    "                continue\n",
    "        if not fip_weather.empty:\n",
    "            #average across the county\n",
    "            precip = fip_weather[fip_weather['datatype']=='PRCP'][['date','value']].rename(columns={'value':'precipitation'})\n",
    "            temp = fip_weather[fip_weather['datatype']=='TOBS'][['date','value']].rename(columns={'value':'temp'})\n",
    "            w = pd.merge(precip, temp, how ='outer', on ='date') \n",
    "            avgs = pd.merge(w.groupby('date', as_index=False)['precipitation'].mean(),\n",
    "                            w.groupby('date', as_index=False)['temp'].mean(),on='date')\n",
    "            avgs['FIPS']=fip\n",
    "            avgs = avgs.to_dict()\n",
    "\n",
    "            #insert records into MongoDB\n",
    "            a = [{key:value[index] for key,value in avgs.items()}\n",
    "                 for index in range(max(map(len,avgs.values())))]\n",
    "            records.insert_many(a)\n",
    "            print(records.count())\n",
    "        else:\n",
    "            empty_fips.append(fip)\n",
    "    \n",
    "toc= time.perf_counter()\n",
    "print(f\"Run time was {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practice- only with DC zip codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_zips = fips_to_zips['District of Columbia']\n",
    "len(dc_zips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseurl = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?'\n",
    "mytoken = 'NVPWXeGxislWKqThiizoffNjnPtUtAcT'\n",
    "databaseid = 'GHCND'\n",
    "begindate = '2020-03-01'\n",
    "enddate = '2020-05-01'\n",
    "dc_weather = pd.DataFrame()\n",
    "for code in dc_zips[0:100]:\n",
    "    print(code)\n",
    "    try:\n",
    "        newdf = get_weather('ZIP:'+str(code), databaseid,begindate,enddate,mytoken,baseurl)\n",
    "        newdf.insert(0,'ZIP',code)\n",
    "        dc_weather = dc_weather.append(newdf)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip = dc_weather[dc_weather['datatype']=='PRCP'][['ZIP','date','value']].rename(columns={'value':'precipitation'})\n",
    "temp = dc_weather[dc_weather['datatype']=='TOBS'][['date','value']].rename(columns={'value':'temp'})\n",
    "w = pd.merge(precip, temp, how ='outer', on ='date') \n",
    "avgs = pd.merge(w.groupby('date', as_index=False)['precipitation'].mean(),\n",
    "                w.groupby('date', as_index=False)['temp'].mean(), on='date')\n",
    "avgs ['County']='DC'\n",
    "avgs.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld = [{key:value[index] for key,value in a.items()}\n",
    "         for index in range(max(map(len,a.values())))]\n",
    "ld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check whether weather from one ZIP is different across a county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.f_oneway(weather['precipitation'][weather['ZIP'] == weather['ZIP'].unique()[0]],\n",
    "               weather['precipitation'][weather['ZIP'] == weather['ZIP'].unique()[1]],\n",
    "               weather['precipitation'][weather['ZIP'] == weather['ZIP'].unique()[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.f_oneway(weather['temp'][weather['ZIP'] == weather['ZIP'].unique()[0]].dropna(), \n",
    "             weather['temp'][weather['ZIP'] == weather['ZIP'].unique()[1]].dropna(),\n",
    "             weather['temp'][weather['ZIP'] == weather['ZIP'].unique()[2]].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting weather data using the noaa package from github:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = noaa.NOAA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = n.get_observations(20001, 'US',start='2020-04-28',end='2020-04-30')\n",
    "f = pd.DataFrame(forecast)\n",
    "items = ['timestamp','textDescription','temperature','precipitationLast6Hours','relativeHumidity','cloudLayers']\n",
    "f = f[items]\n",
    "f.insert(0,'ZIP',zip_code) #add zip code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_weather = pd.DataFrame(columns = ['ZIP','timestamp','textDescription','temperature','precipitationLast6Hours','relativeHumidity','cloudLayers'])\n",
    "dczips = [20001,20004, 20005, 20036, 20009, 20007, 20010, 20008, 20016]\n",
    "for code in dczips:\n",
    "    forecast = n.get_observations(code, 'US',start='2020-04-28',end='2020-04-30')\n",
    "    for obs in forecast:\n",
    "        time = obs['timestamp']\n",
    "        desc = obs['textDescription']\n",
    "        temp = obs['temperature']['value']\n",
    "        precip = obs['precipitationLast6Hours']['value']\n",
    "        hum = obs['relativeHumidity']['value']\n",
    "        cloud = obs['cloudLayers'][0]['base']['value']\n",
    "    \n",
    "        row = [code,time,desc,temp,precip,hum,cloud]\n",
    "        weather.loc[len(weather)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.to_csv('/Users/samismalling/Documents/mobility-report-data-extractor-master/CovidMobile/data/DC_weather_04_28-04_30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.DataFrame()\n",
    "bad_zips = []\n",
    "for zip_code in fips_to_county['ZIP'][0:200]:\n",
    "    if zip_code not in bad_zips:\n",
    "        print(zip_code)\n",
    "        try:\n",
    "            forecast = n.get_forecasts(zip_code, 'US',hourly = False)\n",
    "            f = pd.DataFrame(forecast)\n",
    "            f = f[['startTime','endTime','temperature','windSpeed','windDirection','shortForecast']]\n",
    "            f.insert(0,'ZIP',zip_code) #add zip code \n",
    "            weather = pd.concat([weather, f], ignore_index = True)\n",
    "        except:\n",
    "            bad_zips.append(zip_code)\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
