{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from state_cleaner import *\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import json\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/samismalling/Documents/mobility-report-data-extractor-master/CovidMobile'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../..')\n",
    "os.chdir('CovidMobile')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_to_county = pd.read_csv('./data/ZIP-COUNTY-FIPS_2017-06.csv')\n",
    "parks = pd.read_csv('./data/parks_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "955"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fips = parks['FIPS'].unique()\n",
    "fips = fips[1:]\n",
    "len(fips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_to_zips = dict()\n",
    "for fip in fips:\n",
    "    fips_to_zips[int(fip)] = list(fips_to_county[fips_to_county['STCOUNTYFP']==fip]['ZIP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(locationid, datasetid, begin_date, end_date, mytoken, base_url):\n",
    "    token = {'token': mytoken}\n",
    "    \n",
    "    #passing as string instead of dict because NOAA API does not like percent encoding\n",
    "    params = 'datasetid='+str(datasetid)+'&'+'locationid='+str(locationid)+'&'+'startdate='+str(begin_date)+'&'+'enddate='+str(end_date)+'&'+'limit=25'+'&datatypeid=TOBS,PRCP'\n",
    "    \n",
    "    r = requests.get(base_url+params, headers=token)\n",
    "    #print(\"Request status code: \"+str(r.status_code))\n",
    "\n",
    "    try:\n",
    "        #results comes in json form. Convert to dataframe\n",
    "        df = pd.DataFrame.from_dict(r.json()['results'])\n",
    "        #print(\"Successfully retrieved \"+str(len(df['station'].unique()))+\" stations\")\n",
    "        dates = pd.to_datetime(df['date'])\n",
    "\n",
    "        return df\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def already_exists(fip):\n",
    "    #Checks to see if the fip data is already in the database\n",
    "    if conn.noaaweather.records.count_documents({ 'FIPS': fip }, limit = 1) != 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "z = dict(itertools.islice(fips_to_zips.items(), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admin', 'config', 'local', 'mydb', 'noaaweather']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pymongo\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "conn=pymongo.MongoClient()\n",
    "db = conn.noaaweather\n",
    "records = db.records\n",
    "conn.list_database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request status code: 200\n"
     ]
    }
   ],
   "source": [
    "baseurl = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?'\n",
    "mytoken = 'NVPWXeGxislWKqThiizoffNjnPtUtAcT'\n",
    "databaseid = 'GHCND'\n",
    "begindate = '2020-03-01'\n",
    "enddate = '2020-05-01'\n",
    "newdf = get_weather('ZIP:'+str(6673), databaseid,begindate,enddate,mytoken,baseurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = fips_to_zips[6053]\n",
    "for code in codes:\n",
    "    try:\n",
    "        newdf = get_weather('ZIP:'+str(code), databaseid,begindate,enddate,mytoken,baseurl)\n",
    "        fip_weather = fip_weather.append(newdf)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_fips = [9001,9003,9005,9007,9009,9011,9013,9015,22075,22095,23001,23003,23005,23007,\n",
    "              23009,23011,23017,23019,23025,23031,25001,25003,25005,25009,25011,25013,25015,\n",
    "              25017,25021,25023,25025,25027,26025,39133,39141,39151,39153,39155,39165,39173,\n",
    "              40017,40021,40027,40031,40037,40047,40049,40089,40099,40101,40109,40113,40119,\n",
    "              40121,40125,40131,40143,40151,41003,41005,41007,41009,41011,41015,41017,41019,\n",
    "              41027,41029,41033,41035,41039,41041,41043,41047,41051,41053,41057,41059,41065,\n",
    "              41067,41071,42001,42003,42007,42011,42013,42017,42019,42025,42027,42029,42033,\n",
    "              42041,42043,42045,42049,42051,42055,42069,42071,42073,42075,42077,42079,42081,\n",
    "              42089,42091,42095,42101,42107,42111,42115,42123,42125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33001\n",
      "33003\n",
      "33005\n",
      "33007\n",
      "33009\n",
      "33011\n",
      "33013\n",
      "33015\n",
      "33017\n",
      "34001\n",
      "34003\n",
      "34005\n",
      "34007\n",
      "34009\n",
      "34011\n",
      "34013\n",
      "34015\n",
      "34017\n",
      "34019\n",
      "34021\n",
      "34023\n",
      "34025\n",
      "34027\n",
      "34029\n",
      "34031\n",
      "34033\n",
      "34035\n",
      "34037\n",
      "34039\n",
      "34041\n",
      "36005\n",
      "36071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:33: DeprecationWarning: count is deprecated. Use estimated_document_count or count_documents instead. Please note that $where must be replaced by $expr, $near must be replaced by $geoWithin with $center, and $nearSphere must be replaced by $geoWithin with $centerSphere\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15885\n",
      "36075\n",
      "15929\n",
      "36079\n",
      "15976\n",
      "36081\n",
      "16017\n",
      "36083\n",
      "16045\n",
      "36085\n",
      "16071\n",
      "36087\n",
      "16096\n",
      "36091\n",
      "16129\n",
      "36093\n",
      "16157\n",
      "36089\n",
      "16195\n",
      "36101\n",
      "16237\n",
      "36103\n",
      "16288\n",
      "36109\n",
      "16313\n",
      "36111\n",
      "16340\n",
      "36113\n",
      "16373\n",
      "36119\n",
      "16426\n",
      "37001\n",
      "16453\n",
      "37013\n",
      "16478\n",
      "37017\n",
      "16509\n",
      "37019\n",
      "16542\n",
      "37021\n",
      "16573\n",
      "37023\n",
      "16615\n",
      "37025\n",
      "16643\n",
      "37027\n",
      "16664\n",
      "37031\n",
      "16695\n",
      "37035\n",
      "16739\n",
      "37037\n",
      "16768\n",
      "37045\n",
      "16804\n",
      "37049\n",
      "16817\n",
      "37051\n",
      "16842\n",
      "37055\n",
      "16868\n",
      "37057\n",
      "16910\n",
      "37063\n",
      "16946\n",
      "37067\n",
      "16985\n",
      "37071\n",
      "17021\n",
      "37079\n",
      "17053\n",
      "37081\n",
      "17109\n",
      "37085\n",
      "17138\n",
      "37087\n",
      "17163\n",
      "37089\n",
      "17196\n",
      "37097\n",
      "17230\n",
      "37099\n",
      "17255\n",
      "37101\n",
      "17284\n",
      "37109\n",
      "17325\n",
      "37113\n",
      "17338\n",
      "37111\n",
      "17363\n",
      "37119\n",
      "17398\n",
      "37123\n",
      "17449\n",
      "37125\n",
      "17494\n",
      "37127\n",
      "17534\n",
      "37129\n",
      "17559\n",
      "37133\n",
      "17590\n",
      "37135\n",
      "17623\n",
      "37147\n",
      "17655\n",
      "37151\n",
      "17707\n",
      "37157\n",
      "17746\n",
      "37159\n",
      "17771\n",
      "37161\n",
      "17806\n",
      "37169\n",
      "17845\n",
      "37171\n",
      "17881\n",
      "37173\n",
      "17894\n",
      "37175\n",
      "17919\n",
      "37179\n",
      "17954\n",
      "37183\n",
      "18000\n",
      "37189\n",
      "18013\n",
      "37191\n",
      "18038\n",
      "37193\n",
      "18081\n",
      "37195\n",
      "18117\n",
      "38015\n",
      "18168\n",
      "38017\n",
      "18211\n",
      "38025\n",
      "18260\n",
      "38035\n",
      "18299\n",
      "39003\n",
      "18331\n",
      "39007\n",
      "18356\n",
      "39017\n",
      "18398\n",
      "39025\n",
      "18438\n",
      "39035\n",
      "18495\n",
      "39041\n",
      "18535\n",
      "39043\n",
      "18594\n",
      "39045\n",
      "18640\n",
      "39049\n",
      "18683\n",
      "39055\n",
      "18713\n",
      "39057\n",
      "18770\n",
      "39061\n",
      "18812\n",
      "39073\n",
      "18843\n",
      "39085\n",
      "18868\n",
      "39089\n",
      "18911\n",
      "39093\n",
      "18955\n",
      "39095\n",
      "18996\n",
      "39099\n",
      "19021\n",
      "39109\n",
      "19052\n",
      "39113\n",
      "19095\n",
      "39133\n",
      "39141\n",
      "39151\n",
      "39153\n",
      "39155\n",
      "39165\n",
      "39173\n",
      "40017\n",
      "40021\n",
      "40027\n",
      "40031\n",
      "40037\n",
      "40047\n",
      "40049\n",
      "40089\n",
      "40099\n",
      "40101\n",
      "40109\n",
      "40113\n",
      "40119\n",
      "40121\n",
      "40125\n",
      "40131\n",
      "40143\n",
      "40151\n",
      "41003\n",
      "41005\n",
      "41007\n",
      "41009\n",
      "41011\n",
      "41015\n",
      "41017\n",
      "41019\n",
      "41027\n",
      "41029\n",
      "41033\n",
      "41035\n",
      "41039\n",
      "41041\n",
      "41043\n",
      "41047\n",
      "41051\n",
      "41053\n",
      "41057\n",
      "41059\n",
      "41065\n",
      "41067\n",
      "41071\n",
      "42001\n",
      "42003\n",
      "42007\n",
      "42011\n",
      "42013\n",
      "42017\n",
      "42019\n",
      "42025\n",
      "42027\n",
      "42029\n",
      "42033\n",
      "42041\n",
      "42043\n",
      "42045\n",
      "42049\n",
      "42051\n",
      "42055\n",
      "42069\n",
      "42071\n",
      "42073\n",
      "42075\n",
      "42077\n",
      "42079\n",
      "42081\n",
      "42089\n",
      "42091\n",
      "42095\n",
      "42101\n",
      "42107\n",
      "42111\n",
      "42115\n",
      "42123\n",
      "42125\n",
      "42129\n",
      "19120\n",
      "42133\n",
      "19165\n",
      "44003\n",
      "44005\n",
      "44007\n",
      "44009\n",
      "45003\n",
      "19173\n",
      "45007\n",
      "19200\n",
      "45013\n",
      "19225\n",
      "45015\n"
     ]
    }
   ],
   "source": [
    "baseurl = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?'\n",
    "mytoken = 'NVPWXeGxislWKqThiizoffNjnPtUtAcT'\n",
    "databaseid = 'GHCND'\n",
    "begindate = '2020-03-01'\n",
    "enddate = '2020-05-01'\n",
    "\n",
    "tic = time.perf_counter()\n",
    "weather = pd.DataFrame()\n",
    "for fip, codes in fips_to_zips.items():\n",
    "    if not already_exists(fip) and fip not in empty_fips: #check to make sure not double counting data\n",
    "        print(fip)\n",
    "        fip_weather = pd.DataFrame()\n",
    "        for code in codes:\n",
    "            try:\n",
    "                newdf = get_weather('ZIP:'+str(code), databaseid,begindate,enddate,mytoken,baseurl)\n",
    "                fip_weather = fip_weather.append(newdf)\n",
    "            except:\n",
    "                continue\n",
    "        if not fip_weather.empty:\n",
    "            #average across the county\n",
    "            precip = fip_weather[fip_weather['datatype']=='PRCP'][['date','value']].rename(columns={'value':'precipitation'})\n",
    "            temp = fip_weather[fip_weather['datatype']=='TOBS'][['date','value']].rename(columns={'value':'temp'})\n",
    "            w = pd.merge(precip, temp, how ='outer', on ='date') \n",
    "            avgs = pd.merge(w.groupby('date', as_index=False)['precipitation'].mean(),\n",
    "                            w.groupby('date', as_index=False)['temp'].mean(),on='date')\n",
    "            avgs['FIPS']=fip\n",
    "            avgs = avgs.to_dict()\n",
    "\n",
    "            #insert records into MongoDB\n",
    "            a = [{key:value[index] for key,value in avgs.items()}\n",
    "                 for index in range(max(map(len,avgs.values())))]\n",
    "            records.insert_many(a)\n",
    "            print(records.count())\n",
    "        else:\n",
    "            empty_fips.append(fip)\n",
    "    \n",
    "toc= time.perf_counter()\n",
    "print(f\"Run time was {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practice- only with DC zip codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_zips = fips_to_zips['District of Columbia']\n",
    "len(dc_zips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseurl = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?'\n",
    "mytoken = 'NVPWXeGxislWKqThiizoffNjnPtUtAcT'\n",
    "databaseid = 'GHCND'\n",
    "begindate = '2020-03-01'\n",
    "enddate = '2020-05-01'\n",
    "dc_weather = pd.DataFrame()\n",
    "for code in dc_zips[0:100]:\n",
    "    print(code)\n",
    "    try:\n",
    "        newdf = get_weather('ZIP:'+str(code), databaseid,begindate,enddate,mytoken,baseurl)\n",
    "        newdf.insert(0,'ZIP',code)\n",
    "        dc_weather = dc_weather.append(newdf)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip = dc_weather[dc_weather['datatype']=='PRCP'][['ZIP','date','value']].rename(columns={'value':'precipitation'})\n",
    "temp = dc_weather[dc_weather['datatype']=='TOBS'][['date','value']].rename(columns={'value':'temp'})\n",
    "w = pd.merge(precip, temp, how ='outer', on ='date') \n",
    "avgs = pd.merge(w.groupby('date', as_index=False)['precipitation'].mean(),\n",
    "                w.groupby('date', as_index=False)['temp'].mean(), on='date')\n",
    "avgs ['County']='DC'\n",
    "avgs.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld = [{key:value[index] for key,value in a.items()}\n",
    "         for index in range(max(map(len,a.values())))]\n",
    "ld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check whether weather from one ZIP is different across a county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.f_oneway(weather['precipitation'][weather['ZIP'] == weather['ZIP'].unique()[0]],\n",
    "               weather['precipitation'][weather['ZIP'] == weather['ZIP'].unique()[1]],\n",
    "               weather['precipitation'][weather['ZIP'] == weather['ZIP'].unique()[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.f_oneway(weather['temp'][weather['ZIP'] == weather['ZIP'].unique()[0]].dropna(), \n",
    "             weather['temp'][weather['ZIP'] == weather['ZIP'].unique()[1]].dropna(),\n",
    "             weather['temp'][weather['ZIP'] == weather['ZIP'].unique()[2]].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting weather data using the noaa package from github:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = noaa.NOAA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = n.get_observations(20001, 'US',start='2020-04-28',end='2020-04-30')\n",
    "f = pd.DataFrame(forecast)\n",
    "items = ['timestamp','textDescription','temperature','precipitationLast6Hours','relativeHumidity','cloudLayers']\n",
    "f = f[items]\n",
    "f.insert(0,'ZIP',zip_code) #add zip code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_weather = pd.DataFrame(columns = ['ZIP','timestamp','textDescription','temperature','precipitationLast6Hours','relativeHumidity','cloudLayers'])\n",
    "dczips = [20001,20004, 20005, 20036, 20009, 20007, 20010, 20008, 20016]\n",
    "for code in dczips:\n",
    "    forecast = n.get_observations(code, 'US',start='2020-04-28',end='2020-04-30')\n",
    "    for obs in forecast:\n",
    "        time = obs['timestamp']\n",
    "        desc = obs['textDescription']\n",
    "        temp = obs['temperature']['value']\n",
    "        precip = obs['precipitationLast6Hours']['value']\n",
    "        hum = obs['relativeHumidity']['value']\n",
    "        cloud = obs['cloudLayers'][0]['base']['value']\n",
    "    \n",
    "        row = [code,time,desc,temp,precip,hum,cloud]\n",
    "        weather.loc[len(weather)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.to_csv('/Users/samismalling/Documents/mobility-report-data-extractor-master/CovidMobile/data/DC_weather_04_28-04_30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.DataFrame()\n",
    "bad_zips = []\n",
    "for zip_code in fips_to_county['ZIP'][0:200]:\n",
    "    if zip_code not in bad_zips:\n",
    "        print(zip_code)\n",
    "        try:\n",
    "            forecast = n.get_forecasts(zip_code, 'US',hourly = False)\n",
    "            f = pd.DataFrame(forecast)\n",
    "            f = f[['startTime','endTime','temperature','windSpeed','windDirection','shortForecast']]\n",
    "            f.insert(0,'ZIP',zip_code) #add zip code \n",
    "            weather = pd.concat([weather, f], ignore_index = True)\n",
    "        except:\n",
    "            bad_zips.append(zip_code)\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
