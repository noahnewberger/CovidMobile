{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from state_cleaner import *\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import json\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/samismalling/Documents/mobility-report-data-extractor-master/CovidMobile'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../..')\n",
    "os.chdir('CovidMobile')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_to_county = pd.read_csv('./data/ZIP-COUNTY-FIPS_2017-06.csv')\n",
    "parks = pd.read_csv('./data/parks_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "955"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fips = parks['FIPS'].unique()\n",
    "fips = fips[1:]\n",
    "len(fips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_to_zips = dict()\n",
    "for fip in fips:\n",
    "    fips_to_zips[int(fip)] = list(fips_to_county[fips_to_county['STCOUNTYFP']==fip]['ZIP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(locationid, datasetid, begin_date, end_date, mytoken, base_url):\n",
    "    token = {'token': mytoken}\n",
    "    \n",
    "    #passing as string instead of dict because NOAA API does not like percent encoding\n",
    "    params = 'datasetid='+str(datasetid)+'&'+'locationid='+str(locationid)+'&'+'startdate='+str(begin_date)+'&'+'enddate='+str(end_date)+'&'+'limit=25'+'&datatypeid=TOBS,PRCP'\n",
    "    \n",
    "    r = requests.get(base_url+params, headers=token)\n",
    "    #print(\"Request status code: \"+str(r.status_code))\n",
    "\n",
    "    try:\n",
    "        #results comes in json form. Convert to dataframe\n",
    "        df = pd.DataFrame.from_dict(r.json()['results'])\n",
    "        #print(\"Successfully retrieved \"+str(len(df['station'].unique()))+\" stations\")\n",
    "        dates = pd.to_datetime(df['date'])\n",
    "\n",
    "        return df\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def already_exists(fip):\n",
    "    #Checks to see if the fip data is already in the database\n",
    "    if conn.noaaweather.records.count_documents({ 'FIPS': fip }, limit = 1) != 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "z = dict(itertools.islice(fips_to_zips.items(), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admin', 'config', 'local', 'mydb', 'noaaweather']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pymongo\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "conn=pymongo.MongoClient()\n",
    "db = conn.noaaweather\n",
    "records = db.records\n",
    "conn.list_database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request status code: 200\n"
     ]
    }
   ],
   "source": [
    "baseurl = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?'\n",
    "mytoken = 'NVPWXeGxislWKqThiizoffNjnPtUtAcT'\n",
    "databaseid = 'GHCND'\n",
    "begindate = '2020-03-01'\n",
    "enddate = '2020-05-01'\n",
    "newdf = get_weather('ZIP:'+str(6673), databaseid,begindate,enddate,mytoken,baseurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = fips_to_zips[6053]\n",
    "for code in codes:\n",
    "    try:\n",
    "        newdf = get_weather('ZIP:'+str(code), databaseid,begindate,enddate,mytoken,baseurl)\n",
    "        fip_weather = fip_weather.append(newdf)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_fips = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9001\n",
      "9003\n",
      "9005\n",
      "9007\n",
      "9009\n",
      "9011\n",
      "9013\n",
      "9015\n",
      "22075\n",
      "22095\n",
      "23001\n",
      "23003\n",
      "23005\n",
      "23007\n",
      "23009\n",
      "23011\n",
      "23017\n",
      "23019\n",
      "23025\n",
      "23031\n",
      "24005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:33: DeprecationWarning: count is deprecated. Use estimated_document_count or count_documents instead. Please note that $where must be replaced by $expr, $near must be replaced by $geoWithin with $center, and $nearSphere must be replaced by $geoWithin with $centerSphere\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10643\n",
      "24009\n",
      "10689\n",
      "24013\n",
      "10728\n",
      "24015\n",
      "10753\n",
      "24017\n",
      "10782\n",
      "24021\n",
      "10821\n",
      "24025\n",
      "10871\n",
      "24027\n",
      "10913\n",
      "24031\n",
      "10957\n",
      "24033\n",
      "10998\n",
      "24035\n",
      "11027\n",
      "24037\n",
      "11074\n",
      "24043\n",
      "11103\n",
      "24047\n",
      "11128\n",
      "25001\n",
      "25003\n",
      "25005\n",
      "25009\n",
      "25011\n",
      "25013\n",
      "25015\n",
      "25017\n",
      "25021\n",
      "25023\n",
      "25025\n",
      "25027\n",
      "26003\n",
      "11142\n",
      "26005\n",
      "11194\n",
      "26017\n",
      "11208\n",
      "26021\n",
      "11236\n",
      "26025\n"
     ]
    }
   ],
   "source": [
    "baseurl = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?'\n",
    "mytoken = 'NVPWXeGxislWKqThiizoffNjnPtUtAcT'\n",
    "databaseid = 'GHCND'\n",
    "begindate = '2020-03-01'\n",
    "enddate = '2020-05-01'\n",
    "\n",
    "tic = time.perf_counter()\n",
    "weather = pd.DataFrame()\n",
    "for fip, codes in fips_to_zips.items():\n",
    "    if not already_exists(fip) and fip not in empty_fips: #check to make sure not double counting data\n",
    "        print(fip)\n",
    "        fip_weather = pd.DataFrame()\n",
    "        for code in codes:\n",
    "            try:\n",
    "                newdf = get_weather('ZIP:'+str(code), databaseid,begindate,enddate,mytoken,baseurl)\n",
    "                fip_weather = fip_weather.append(newdf)\n",
    "            except:\n",
    "                continue\n",
    "        if not fip_weather.empty:\n",
    "            #average across the county\n",
    "            precip = fip_weather[fip_weather['datatype']=='PRCP'][['date','value']].rename(columns={'value':'precipitation'})\n",
    "            temp = fip_weather[fip_weather['datatype']=='TOBS'][['date','value']].rename(columns={'value':'temp'})\n",
    "            w = pd.merge(precip, temp, how ='outer', on ='date') \n",
    "            avgs = pd.merge(w.groupby('date', as_index=False)['precipitation'].mean(),\n",
    "                            w.groupby('date', as_index=False)['temp'].mean(),on='date')\n",
    "            avgs['FIPS']=fip\n",
    "            avgs = avgs.to_dict()\n",
    "\n",
    "            #insert records into MongoDB\n",
    "            a = [{key:value[index] for key,value in avgs.items()}\n",
    "                 for index in range(max(map(len,avgs.values())))]\n",
    "            records.insert_many(a)\n",
    "            print(records.count())\n",
    "        else:\n",
    "            empty_fips.append(fip)\n",
    "    \n",
    "toc= time.perf_counter()\n",
    "print(f\"Run time was {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practice- only with DC zip codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_zips = fips_to_zips['District of Columbia']\n",
    "len(dc_zips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseurl = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?'\n",
    "mytoken = 'NVPWXeGxislWKqThiizoffNjnPtUtAcT'\n",
    "databaseid = 'GHCND'\n",
    "begindate = '2020-03-01'\n",
    "enddate = '2020-05-01'\n",
    "dc_weather = pd.DataFrame()\n",
    "for code in dc_zips[0:100]:\n",
    "    print(code)\n",
    "    try:\n",
    "        newdf = get_weather('ZIP:'+str(code), databaseid,begindate,enddate,mytoken,baseurl)\n",
    "        newdf.insert(0,'ZIP',code)\n",
    "        dc_weather = dc_weather.append(newdf)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip = dc_weather[dc_weather['datatype']=='PRCP'][['ZIP','date','value']].rename(columns={'value':'precipitation'})\n",
    "temp = dc_weather[dc_weather['datatype']=='TOBS'][['date','value']].rename(columns={'value':'temp'})\n",
    "w = pd.merge(precip, temp, how ='outer', on ='date') \n",
    "avgs = pd.merge(w.groupby('date', as_index=False)['precipitation'].mean(),\n",
    "                w.groupby('date', as_index=False)['temp'].mean(), on='date')\n",
    "avgs ['County']='DC'\n",
    "avgs.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld = [{key:value[index] for key,value in a.items()}\n",
    "         for index in range(max(map(len,a.values())))]\n",
    "ld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check whether weather from one ZIP is different across a county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.f_oneway(weather['precipitation'][weather['ZIP'] == weather['ZIP'].unique()[0]],\n",
    "               weather['precipitation'][weather['ZIP'] == weather['ZIP'].unique()[1]],\n",
    "               weather['precipitation'][weather['ZIP'] == weather['ZIP'].unique()[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.f_oneway(weather['temp'][weather['ZIP'] == weather['ZIP'].unique()[0]].dropna(), \n",
    "             weather['temp'][weather['ZIP'] == weather['ZIP'].unique()[1]].dropna(),\n",
    "             weather['temp'][weather['ZIP'] == weather['ZIP'].unique()[2]].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting weather data using the noaa package from github:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = noaa.NOAA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = n.get_observations(20001, 'US',start='2020-04-28',end='2020-04-30')\n",
    "f = pd.DataFrame(forecast)\n",
    "items = ['timestamp','textDescription','temperature','precipitationLast6Hours','relativeHumidity','cloudLayers']\n",
    "f = f[items]\n",
    "f.insert(0,'ZIP',zip_code) #add zip code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_weather = pd.DataFrame(columns = ['ZIP','timestamp','textDescription','temperature','precipitationLast6Hours','relativeHumidity','cloudLayers'])\n",
    "dczips = [20001,20004, 20005, 20036, 20009, 20007, 20010, 20008, 20016]\n",
    "for code in dczips:\n",
    "    forecast = n.get_observations(code, 'US',start='2020-04-28',end='2020-04-30')\n",
    "    for obs in forecast:\n",
    "        time = obs['timestamp']\n",
    "        desc = obs['textDescription']\n",
    "        temp = obs['temperature']['value']\n",
    "        precip = obs['precipitationLast6Hours']['value']\n",
    "        hum = obs['relativeHumidity']['value']\n",
    "        cloud = obs['cloudLayers'][0]['base']['value']\n",
    "    \n",
    "        row = [code,time,desc,temp,precip,hum,cloud]\n",
    "        weather.loc[len(weather)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.to_csv('/Users/samismalling/Documents/mobility-report-data-extractor-master/CovidMobile/data/DC_weather_04_28-04_30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.DataFrame()\n",
    "bad_zips = []\n",
    "for zip_code in fips_to_county['ZIP'][0:200]:\n",
    "    if zip_code not in bad_zips:\n",
    "        print(zip_code)\n",
    "        try:\n",
    "            forecast = n.get_forecasts(zip_code, 'US',hourly = False)\n",
    "            f = pd.DataFrame(forecast)\n",
    "            f = f[['startTime','endTime','temperature','windSpeed','windDirection','shortForecast']]\n",
    "            f.insert(0,'ZIP',zip_code) #add zip code \n",
    "            weather = pd.concat([weather, f], ignore_index = True)\n",
    "        except:\n",
    "            bad_zips.append(zip_code)\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
