{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from state_cleaner import *\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import json\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/samismalling/CovidMobile'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../..')\n",
    "os.chdir('CovidMobile')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (104,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,139,140,143,144) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "fips_to_county = pd.read_csv('./data/ZIP-COUNTY-FIPS_2017-06.csv')\n",
    "full_data = pd.read_csv('./data/compiled_2020-05-22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks = full_data[['FIPS','park']][full_data['park'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1008"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fips = parks['FIPS'].unique()\n",
    "len(fips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_to_zips = dict()\n",
    "for fip in fips:\n",
    "    fips_to_zips[int(fip)] = list(fips_to_county[fips_to_county['STCOUNTYFP']==fip]['ZIP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(locationid, datasetid, begin_date, end_date, mytoken, base_url):\n",
    "    token = {'token': mytoken}\n",
    "    \n",
    "    #passing as string instead of dict because NOAA API does not like percent encoding\n",
    "    params = 'datasetid='+str(datasetid)+'&'+'locationid='+str(locationid)+'&'+'startdate='+str(begin_date)+'&'+'enddate='+str(end_date)+'&'+'limit=15'+'&datatypeid=TMIN,TMAX,PRCP'\n",
    "    \n",
    "    r = requests.get(base_url+params, headers=token)\n",
    "    #print(\"Request status code: \"+str(r.status_code))\n",
    "\n",
    "    try:\n",
    "        #results comes in json form. Convert to dataframe\n",
    "        df = pd.DataFrame.from_dict(r.json()['results'])\n",
    "        #print(\"Successfully retrieved \"+str(len(df['station'].unique()))+\" stations\")\n",
    "        dates = pd.to_datetime(df['date'])\n",
    "\n",
    "        return df\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fip_already_exists(fip):\n",
    "    #Checks to see if the fip data is already in the database\n",
    "    if conn.noaaweather.records.count_documents({ 'FIPS': fip }, limit = 1) != 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_fip_already_exists(fip,date):\n",
    "    #Checks to see if the fip data for a specific date is already in the database\n",
    "    if conn.noaaweather.records.count_documents({ 'FIPS': fip , 'date':date+'T00:00:00'}, limit = 1) != 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admin', 'config', 'local']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pymongo\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "conn=pymongo.MongoClient()\n",
    "db = conn.noaaweather\n",
    "records = db.records\n",
    "conn.list_database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_fips = [9001,9003,9005,9007,9009,9011,9013,9015,22075,22095,23001,23003,23005,23007,\n",
    "              23009,23011,23017,23019,23025,23031,25001,25003,25005,25009,25011,25013,25015,\n",
    "              25017,25021,25023,25025,25027,26025,39133,39141,39151,39153,39155,39165,39173,\n",
    "              40017,40021,40027,40031,40037,40047,40049,40089,40099,40101,40109,40113,40119,\n",
    "              40121,40125,40131,40143,40151,41003,41005,41007,41009,41011,41015,41017,41019,\n",
    "              41027,41029,41033,41035,41039,41041,41043,41047,41051,41053,41057,41059,41065,\n",
    "              41067,41071,42001,42003,42007,42011,42013,42017,42019,42025,42027,42029,42033,\n",
    "              42041,42043,42045,42049,42051,42055,42069,42071,42073,42075,42077,42079,42081,\n",
    "              42089,42091,42095,42101,42107,42111,42115,42123,42125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_fips = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18117\n"
     ]
    }
   ],
   "source": [
    "baseurl = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?'\n",
    "mytoken = 'NVPWXeGxislWKqThiizoffNjnPtUtAcT'\n",
    "databaseid = 'GHCND'\n",
    "begindate = '2020-02-15'\n",
    "enddate = '2020-05-17'\n",
    "\n",
    "tic = time.perf_counter()\n",
    "weather = pd.DataFrame()\n",
    "for fip, codes in fips_to_zips.items():\n",
    "    fip_weather = pd.DataFrame()\n",
    "    if not fip_already_exists(fip) and fip not in empty_fips: #check to make sure not double counting data\n",
    "        print(fip)\n",
    "        for code in codes:\n",
    "            try:\n",
    "                newdf = get_weather('ZIP:'+str(code), databaseid,begindate,enddate,mytoken,baseurl)\n",
    "                fip_weather = fip_weather.append(newdf)\n",
    "            except:\n",
    "                continue\n",
    "    if not fip_weather.empty:\n",
    "        #average across the county\n",
    "        precip = fip_weather[fip_weather['datatype']=='PRCP'][['date','value']].rename(columns={'value':'precipitation'})\n",
    "        min_temp = fip_weather[fip_weather['datatype']=='TMIN'][['date','value']].rename(columns={'value':'min_temp'})\n",
    "        max_temp = fip_weather[fip_weather['datatype']=='TMAX'][['date','value']].rename(columns={'value':'max_temp'})\n",
    "        w = pd.merge(precip, temp, how ='outer', on ='date') \n",
    "        avgs = pd.merge(w.groupby('date', as_index=False)['precipitation'].mean(),\n",
    "                        w.groupby('date', as_index=False)['min_temp'].mean(),\n",
    "                        w.groupby('date', as_index=False)['max_temp'].mean(),on='date')\n",
    "        avgs['FIPS']=fip\n",
    "        avgs = avgs.to_dict()\n",
    "\n",
    "        #insert records into MongoDB\n",
    "        a = [{key:value[index] for key,value in avgs.items()}\n",
    "             for index in range(max(map(len,avgs.values())))]\n",
    "        #only insert records which are not already there:\n",
    "        for line in a:\n",
    "            if not date_fip_already_exists(line['FIPS'],line['date']):\n",
    "                records.insert_one(line)\n",
    "        print(records.count())\n",
    "    else:\n",
    "        empty_fips.append(fip)\n",
    "\n",
    "toc= time.perf_counter()\n",
    "print(f\"Run time was {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practice- only with zip codes from FIP 1001:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zips = fips_to_zips[1001]\n",
    "len(zips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36003\n",
      "36006\n",
      "36067\n"
     ]
    }
   ],
   "source": [
    "baseurl = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?'\n",
    "mytoken = 'NVPWXeGxislWKqThiizoffNjnPtUtAcT'\n",
    "databaseid = 'GHCND'\n",
    "begindate = '2020-03-01'\n",
    "enddate = '2020-05-01'\n",
    "weather = pd.DataFrame()\n",
    "for code in zips[0:3]:\n",
    "    print(code)\n",
    "    try:\n",
    "        newdf = get_weather('ZIP:'+str(code),databaseid,begindate,enddate,mytoken,baseurl)\n",
    "        newdf.insert(0,'ZIP',code)\n",
    "        weather = weather.append(newdf)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FIPS': 1001,\n",
       " '_id': ObjectId('5eb444b4f987a45eeb9d9046'),\n",
       " 'date': '2020-03-01T00:00:00',\n",
       " 'precipitation': 0.0,\n",
       " 'temp': 33.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-cf47c53fce39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'token'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmytoken\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'datasetid='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdatabaseid\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'&locationid='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocationid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'&startdate='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbegindate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'&enddate='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menddate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'&limit=15'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'&datatypeid=TMAX,TMIN,PRCP'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseurl\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Request status code: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#df = pd.DataFrame.from_dict(r.json()['results'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    670\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             )\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             )\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "baseurl = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?'\n",
    "mytoken = 'NVPWXeGxislWKqThiizoffNjnPtUtAcT'\n",
    "databaseid = 'GHCND'\n",
    "begindate = '2020-05-01'\n",
    "enddate = '2020-05-01'\n",
    "locationid = 'ZIP:36003'\n",
    "token = {'token': mytoken}\n",
    "params = 'datasetid='+databaseid+'&locationid='+str(locationid)+'&startdate='+str(begindate)+'&enddate='+str(enddate)+'&limit=15'+'&datatypeid=TMAX,TMIN,PRCP'\n",
    "r = requests.get(baseurl+params, headers=token)\n",
    "print(\"Request status code: \"+str(r.status_code))\n",
    "#df = pd.DataFrame.from_dict(r.json()['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = get_weather('ZIP:36003',databaseid,begindate,enddate,mytoken,baseurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip = weather[weather['datatype']=='PRCP'][['ZIP','date','value']].rename(columns={'value':'precipitation'})\n",
    "temp = weather[weather['datatype']=='TOBS'][['date','value']].rename(columns={'value':'temp'})\n",
    "w = pd.merge(precip, temp, how ='outer', on ='date') \n",
    "avgs = pd.merge(w.groupby('date', as_index=False)['precipitation'].mean(),\n",
    "                w.groupby('date', as_index=False)['temp'].mean(), on='date')\n",
    "a = avgs.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'date': '2020-03-01T00:00:00', 'precipitation': 0, 'temp': nan},\n",
       " {'date': '2020-03-02T00:00:00', 'precipitation': 127, 'temp': nan},\n",
       " {'date': '2020-03-03T00:00:00', 'precipitation': 592, 'temp': nan},\n",
       " {'date': '2020-03-04T00:00:00', 'precipitation': 483, 'temp': nan},\n",
       " {'date': '2020-03-05T00:00:00', 'precipitation': 376, 'temp': nan},\n",
       " {'date': '2020-03-06T00:00:00', 'precipitation': 0, 'temp': nan},\n",
       " {'date': '2020-03-07T00:00:00', 'precipitation': 0, 'temp': nan},\n",
       " {'date': '2020-03-08T00:00:00', 'precipitation': 0, 'temp': nan},\n",
       " {'date': '2020-03-09T00:00:00', 'precipitation': 0, 'temp': nan},\n",
       " {'date': '2020-03-10T00:00:00', 'precipitation': 81, 'temp': nan},\n",
       " {'date': '2020-03-11T00:00:00', 'precipitation': 3, 'temp': nan},\n",
       " {'date': '2020-03-12T00:00:00', 'precipitation': 0, 'temp': nan},\n",
       " {'date': '2020-03-13T00:00:00', 'precipitation': 0, 'temp': nan},\n",
       " {'date': '2020-03-14T00:00:00', 'precipitation': 0, 'temp': nan},\n",
       " {'date': '2020-03-15T00:00:00', 'precipitation': 0, 'temp': nan},\n",
       " {'date': '2020-03-16T00:00:00', 'precipitation': 0, 'temp': nan},\n",
       " {'date': '2020-03-17T00:00:00', 'precipitation': 0, 'temp': nan},\n",
       " {'date': '2020-03-18T00:00:00', 'precipitation': 0, 'temp': nan},\n",
       " {'date': '2020-03-19T00:00:00', 'precipitation': 0, 'temp': nan},\n",
       " {'date': '2020-03-20T00:00:00', 'precipitation': 0, 'temp': nan},\n",
       " {'date': '2020-03-21T00:00:00', 'precipitation': 76, 'temp': nan},\n",
       " {'date': '2020-03-22T00:00:00', 'precipitation': 48, 'temp': nan},\n",
       " {'date': '2020-03-23T00:00:00', 'precipitation': 3, 'temp': nan},\n",
       " {'date': '2020-03-24T00:00:00', 'precipitation': 0, 'temp': nan},\n",
       " {'date': '2020-03-25T00:00:00', 'precipitation': 0, 'temp': nan}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld = [{key:value[index] for key,value in a.items()}\n",
    "         for index in range(max(map(len,a.values())))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': '2020-03-01T00:00:00', 'precipitation': 0, 'temp': nan}\n",
      "{'date': '2020-03-02T00:00:00', 'precipitation': 127, 'temp': nan}\n",
      "{'date': '2020-03-03T00:00:00', 'precipitation': 592, 'temp': nan}\n",
      "{'date': '2020-03-04T00:00:00', 'precipitation': 483, 'temp': nan}\n",
      "{'date': '2020-03-05T00:00:00', 'precipitation': 376, 'temp': nan}\n",
      "{'date': '2020-03-06T00:00:00', 'precipitation': 0, 'temp': nan}\n",
      "{'date': '2020-03-07T00:00:00', 'precipitation': 0, 'temp': nan}\n",
      "{'date': '2020-03-08T00:00:00', 'precipitation': 0, 'temp': nan}\n",
      "{'date': '2020-03-09T00:00:00', 'precipitation': 0, 'temp': nan}\n",
      "{'date': '2020-03-10T00:00:00', 'precipitation': 81, 'temp': nan}\n",
      "{'date': '2020-03-11T00:00:00', 'precipitation': 3, 'temp': nan}\n",
      "{'date': '2020-03-12T00:00:00', 'precipitation': 0, 'temp': nan}\n",
      "{'date': '2020-03-13T00:00:00', 'precipitation': 0, 'temp': nan}\n",
      "{'date': '2020-03-14T00:00:00', 'precipitation': 0, 'temp': nan}\n",
      "{'date': '2020-03-15T00:00:00', 'precipitation': 0, 'temp': nan}\n",
      "{'date': '2020-03-16T00:00:00', 'precipitation': 0, 'temp': nan}\n",
      "{'date': '2020-03-17T00:00:00', 'precipitation': 0, 'temp': nan}\n",
      "{'date': '2020-03-18T00:00:00', 'precipitation': 0, 'temp': nan}\n",
      "{'date': '2020-03-19T00:00:00', 'precipitation': 0, 'temp': nan}\n",
      "{'date': '2020-03-20T00:00:00', 'precipitation': 0, 'temp': nan}\n",
      "{'date': '2020-03-21T00:00:00', 'precipitation': 76, 'temp': nan}\n",
      "{'date': '2020-03-22T00:00:00', 'precipitation': 48, 'temp': nan}\n",
      "{'date': '2020-03-23T00:00:00', 'precipitation': 3, 'temp': nan}\n",
      "{'date': '2020-03-24T00:00:00', 'precipitation': 0, 'temp': nan}\n",
      "{'date': '2020-03-25T00:00:00', 'precipitation': 0, 'temp': nan}\n"
     ]
    }
   ],
   "source": [
    "for line in ld:\n",
    "    if line['date'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data to CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_sample = list(records.find( {} ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pd.DataFrame(columns=[])\n",
    "for num, doc in enumerate(weather_sample):\n",
    "    # convert ObjectId() to str \n",
    "    doc[\"_id\"] = str(doc[\"_id\"]) \n",
    "\n",
    "    # get document _id from dict \n",
    "    doc_id = doc[\"_id\"]\n",
    "    \n",
    "    # create a Series obj from the MongoDB dict \n",
    "    series_obj = pd.Series( doc, name=doc_id ) \n",
    "\n",
    "    # append the MongoDB Series obj to the DataFrame obj \n",
    "    docs = docs.append( series_obj )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del docs['_id']\n",
    "docs.reset_index(inplace=False)\n",
    "docs = docs.astype({'date':'str'})\n",
    "docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.to_csv('./SafeGraph_data/NOAA_weather_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check whether weather from one ZIP is different across a county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.f_oneway(weather['precipitation'][weather['ZIP'] == weather['ZIP'].unique()[0]],\n",
    "               weather['precipitation'][weather['ZIP'] == weather['ZIP'].unique()[1]],\n",
    "               weather['precipitation'][weather['ZIP'] == weather['ZIP'].unique()[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.f_oneway(weather['temp'][weather['ZIP'] == weather['ZIP'].unique()[0]].dropna(), \n",
    "             weather['temp'][weather['ZIP'] == weather['ZIP'].unique()[1]].dropna(),\n",
    "             weather['temp'][weather['ZIP'] == weather['ZIP'].unique()[2]].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting weather data using the noaa package from github:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = noaa.NOAA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = n.get_observations(20001, 'US',start='2020-04-28',end='2020-04-30')\n",
    "f = pd.DataFrame(forecast)\n",
    "items = ['timestamp','textDescription','temperature','precipitationLast6Hours','relativeHumidity','cloudLayers']\n",
    "f = f[items]\n",
    "f.insert(0,'ZIP',zip_code) #add zip code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_weather = pd.DataFrame(columns = ['ZIP','timestamp','textDescription','temperature','precipitationLast6Hours','relativeHumidity','cloudLayers'])\n",
    "dczips = [20001,20004, 20005, 20036, 20009, 20007, 20010, 20008, 20016]\n",
    "for code in dczips:\n",
    "    forecast = n.get_observations(code, 'US',start='2020-04-28',end='2020-04-30')\n",
    "    for obs in forecast:\n",
    "        time = obs['timestamp']\n",
    "        desc = obs['textDescription']\n",
    "        temp = obs['temperature']['value']\n",
    "        precip = obs['precipitationLast6Hours']['value']\n",
    "        hum = obs['relativeHumidity']['value']\n",
    "        cloud = obs['cloudLayers'][0]['base']['value']\n",
    "    \n",
    "        row = [code,time,desc,temp,precip,hum,cloud]\n",
    "        weather.loc[len(weather)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.to_csv('/Users/samismalling/Documents/mobility-report-data-extractor-master/CovidMobile/data/DC_weather_04_28-04_30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.DataFrame()\n",
    "bad_zips = []\n",
    "for zip_code in fips_to_county['ZIP'][0:200]:\n",
    "    if zip_code not in bad_zips:\n",
    "        print(zip_code)\n",
    "        try:\n",
    "            forecast = n.get_forecasts(zip_code, 'US',hourly = False)\n",
    "            f = pd.DataFrame(forecast)\n",
    "            f = f[['startTime','endTime','temperature','windSpeed','windDirection','shortForecast']]\n",
    "            f.insert(0,'ZIP',zip_code) #add zip code \n",
    "            weather = pd.concat([weather, f], ignore_index = True)\n",
    "        except:\n",
    "            bad_zips.append(zip_code)\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
